{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36851a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment file loaded: True\n",
      "API Key: ************************************\n",
      "Base URL: https://ark.cn-beijing.volces.com/api/v3\n",
      "Model: deepseek-r1-250528\n",
      "API Key length: 36\n",
      "API Key first 5 chars: 33072\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Clear any existing environment variables first\n",
    "if 'OPENAI_API_KEY' in os.environ:\n",
    "    del os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Load with explicit path and override existing variables\n",
    "result = load_dotenv(override=True, verbose=True)\n",
    "print(f\"Environment file loaded: {result}\")\n",
    "\n",
    "# Verify the configuration is loaded\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "base_url = os.getenv('OPENAI_BASE_URL')\n",
    "model = os.getenv('OPENAI_MODEL')\n",
    "\n",
    "print(f\"API Key: {'*' * len(api_key) if api_key else 'NOT FOUND'}\")\n",
    "print(f\"Base URL: {base_url}\")\n",
    "print(f\"Model: {model}\")\n",
    "\n",
    "# Additional debugging\n",
    "if api_key:\n",
    "    print(f\"API Key length: {len(api_key)}\")\n",
    "    print(f\"API Key first 5 chars: {api_key[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4747883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥ç”Ÿæˆç³»ç»Ÿå·²å¯ç”¨:\n",
      "  âœ“ ä¸¥æ ¼éµå¾ªã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹\n",
      "  âœ“ æå…¶ä¸¥æ ¼çš„è¯„åˆ†æ ‡å‡†ï¼ˆâ‰¥8.5åˆ†æ‰ç®—ä¼˜ç§€ï¼‰\n",
      "  âœ“ æ™ºèƒ½æœç´¢å…³é”®è¯ç”Ÿæˆï¼ˆLLMé©±åŠ¨ï¼‰\n",
      "  âœ“ ä¿®å¤äº†ä¸­æ–‡å…³é”®è¯æœç´¢é—®é¢˜\n",
      "  âœ“ å¢å¼ºçš„å¤šæ¬¡æœç´¢ï¼ˆæœ€å¤š6æ¬¡ï¼Œæ¯æ¬¡æ›´å¤šç»“æœï¼‰\n",
      "  âœ“ ç‹¬ç«‹å›¾è¡¨ç”Ÿæˆå¹¶æ’å…¥Wordæ–‡æ¡£ - ä¿®å¤æ’å…¥é€»è¾‘\n",
      "  âœ“ ä¸­æ–‡å­—ä½“é—®é¢˜å·²ä¿®å¤\n",
      "  âœ“ æœ€å¤š8æ¬¡æ”¹è¿›è¿­ä»£\n",
      "  âœ“ å®Œæ•´çš„åˆè§„æ€§éªŒè¯ä½“ç³»\n",
      "  âœ“ å›¾è¡¨æ–‡ä»¶å­˜åœ¨æ€§éªŒè¯\n",
      "  âœ“ æ™ºèƒ½å›¾è¡¨æ’å…¥ä½ç½®\n"
     ]
    }
   ],
   "source": [
    "# Enhanced patch with China Securities Association compliance and strict formatting\n",
    "import industry_workflow\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import locale\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Configure matplotlib for Chinese font display\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Set locale to handle Chinese characters properly\n",
    "try:\n",
    "    locale.setlocale(locale.LC_ALL, 'zh_CN.UTF-8')\n",
    "except:\n",
    "    try:\n",
    "        locale.setlocale(locale.LC_ALL, 'Chinese_China.utf8')\n",
    "    except:\n",
    "        pass  # Fall back to default locale\n",
    "\n",
    "# Store original functions\n",
    "if not hasattr(industry_workflow, '_original_call_llm'):\n",
    "    industry_workflow._original_call_llm = industry_workflow.call_llm\n",
    "if not hasattr(industry_workflow, '_original_search_web'):\n",
    "    industry_workflow._original_search_web = industry_workflow.search_web\n",
    "\n",
    "def bulletproof_call_llm(prompt: str) -> str:\n",
    "    \"\"\"å®Œå…¨é˜²é”™çš„LLMè°ƒç”¨å‡½æ•°\"\"\"\n",
    "    max_length = 70000\n",
    "    \n",
    "    try:\n",
    "        if len(prompt) > max_length:\n",
    "            print(f\"è¾“å…¥è¿‡é•¿ ({len(prompt)} å­—ç¬¦)ï¼Œæ­£åœ¨æˆªæ–­...\")\n",
    "            prompt = prompt[:max_length]\n",
    "            last_period = prompt.rfind('ã€‚')\n",
    "            if last_period > max_length * 0.8:\n",
    "                prompt = prompt[:last_period + 1]\n",
    "            print(f\"æˆªæ–­åé•¿åº¦: {len(prompt)} å­—ç¬¦\")\n",
    "        \n",
    "        client = openai.OpenAI(\n",
    "            api_key=os.getenv('OPENAI_API_KEY'),\n",
    "            base_url=os.getenv('OPENAI_BASE_URL')\n",
    "        )\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=os.getenv('OPENAI_MODEL', 'deepseek-v3-250324'),\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=16384,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content\n",
    "        return result.strip() if result else \"ç”Ÿæˆå¤±è´¥\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"APIè°ƒç”¨å¤±è´¥: {e}\")\n",
    "        return \"APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å“åº”\"\n",
    "\n",
    "\n",
    "def bulletproof_search_web(term: str):\n",
    "    \"\"\"å®Œå…¨é˜²é”™çš„æœç´¢å‡½æ•°\"\"\"\n",
    "    try:\n",
    "        from duckduckgo_search import DDGS\n",
    "        with DDGS() as ddgs:\n",
    "            results = list(ddgs.text(keywords=term, region=\"cn-zh\", max_results=3))\n",
    "            for result in results:\n",
    "                if 'body' in result:\n",
    "                    result['body'] = result['body'][:500] + \"...\"\n",
    "            return results[:3]\n",
    "    except Exception as e:\n",
    "        print(f\"æœç´¢å¤±è´¥: {e}\")\n",
    "        return [{\"title\": \"æœç´¢å¤±è´¥\", \"body\": \"æ— æ³•è·å–æœç´¢ç»“æœ\", \"href\": \"\"}]\n",
    "\n",
    "def generate_smart_search_terms(industry, search_focus):\n",
    "    \"\"\"ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½æœç´¢å…³é”®è¯\"\"\"\n",
    "    try:\n",
    "        prompt = f\"\"\"\n",
    "ä¸º{industry}è¡Œä¸šç ”ç©¶ç”Ÿæˆæœ€æœ‰æ•ˆçš„æœç´¢å…³é”®è¯ï¼Œé‡ç‚¹å…³æ³¨{search_focus}ã€‚\n",
    "\n",
    "è¯·ç”Ÿæˆ5ä¸ªç²¾ç¡®çš„ä¸­æ–‡æœç´¢å…³é”®è¯ï¼Œæ¯ä¸ªå…³é”®è¯åº”è¯¥ï¼š\n",
    "1. åŒ…å«è¡Œä¸šæ ¸å¿ƒæœ¯è¯­\n",
    "2. é’ˆå¯¹{search_focus}çš„å…·ä½“å†…å®¹\n",
    "3. é€‚åˆåœ¨ä¸­æ–‡æœç´¢å¼•æ“ä¸­ä½¿ç”¨\n",
    "4. èƒ½å¤Ÿè·å¾—æƒå¨ã€ä¸“ä¸šçš„æœç´¢ç»“æœ\n",
    "\n",
    "è¡Œä¸š: {industry}\n",
    "æœç´¢é‡ç‚¹: {search_focus}\n",
    "\n",
    "è¯·ç›´æ¥è¿”å›5ä¸ªæœç´¢å…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦å…¶ä»–è¯´æ˜ï¼š\n",
    "\"\"\"\n",
    "        \n",
    "        response = bulletproof_call_llm(prompt)\n",
    "        keywords = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "        \n",
    "        # ç¡®ä¿è‡³å°‘æœ‰ä¸€äº›åŸºç¡€å…³é”®è¯\n",
    "        if not keywords:\n",
    "            if 'ç”Ÿå‘½å‘¨æœŸ' in search_focus:\n",
    "                keywords = [\n",
    "                    f\"{industry}å¸‚åœºè§„æ¨¡\",\n",
    "                    f\"{industry}å‘å±•ç°çŠ¶\",\n",
    "                    f\"{industry}å¢é•¿è¶‹åŠ¿\",\n",
    "                    f\"{industry}è¡Œä¸šæŠ¥å‘Š\",\n",
    "                    f\"{industry}å‘å±•é˜¶æ®µ\"\n",
    "                ]\n",
    "            elif 'äº§ä¸šé“¾' in search_focus or 'ç»“æ„' in search_focus:\n",
    "                keywords = [\n",
    "                    f\"{industry}äº§ä¸šé“¾\",\n",
    "                    f\"{industry}ç«äº‰æ ¼å±€\",\n",
    "                    f\"{industry}å¸‚åœºç»“æ„\",\n",
    "                    f\"{industry}ä¸»è¦ä¼ä¸š\",\n",
    "                    f\"{industry}ä¸Šä¸‹æ¸¸\"\n",
    "                ]\n",
    "            else:\n",
    "                keywords = [\n",
    "                    f\"{industry}å‘å±•è¶‹åŠ¿\",\n",
    "                    f\"{industry}æ”¿ç­–å½±å“\",\n",
    "                    f\"{industry}æŠ€æœ¯åˆ›æ–°\",\n",
    "                    f\"{industry}å¸‚åœºå‰æ™¯\",\n",
    "                    f\"{industry}æŠ•èµ„æœºä¼š\"\n",
    "                ]\n",
    "        \n",
    "        return keywords[:5]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ç”Ÿæˆæœç´¢å…³é”®è¯å¤±è´¥: {e}\")\n",
    "        return [f\"{industry}è¡Œä¸šç ”ç©¶\", f\"{industry}å¸‚åœºåˆ†æ\", f\"{industry}å‘å±•ç°çŠ¶\"]\n",
    "\n",
    "def enhanced_search_web_multiple(terms_list, max_results_per_term=5):\n",
    "    \"\"\"å¢å¼ºçš„å¤šæ¬¡æœç´¢å‡½æ•° - ä¿®å¤æœç´¢å…³é”®è¯å¤„ç†\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # æ­£ç¡®å¤„ç†æœç´¢å…³é”®è¯åˆ—è¡¨\n",
    "    if isinstance(terms_list, str):\n",
    "        search_terms = [terms_list]\n",
    "    elif isinstance(terms_list, list):\n",
    "        search_terms = []\n",
    "        for item in terms_list:\n",
    "            if isinstance(item, str):\n",
    "                search_terms.append(item)\n",
    "            elif isinstance(item, list):\n",
    "                search_terms.extend([str(subitem) for subitem in item if subitem])\n",
    "    else:\n",
    "        search_terms = [str(terms_list)]\n",
    "    \n",
    "    print(f\"ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± {len(search_terms)} ä¸ªå…³é”®è¯\")\n",
    "    \n",
    "    for i, term in enumerate(search_terms):\n",
    "        term = str(term).strip()\n",
    "        if not term:\n",
    "            continue\n",
    "            \n",
    "        print(f\"ğŸ” æœç´¢å…³é”®è¯ ({i+1}/{len(search_terms)}): {term}\")\n",
    "        \n",
    "        try:\n",
    "            # ä½¿ç”¨æ­£ç¡®çš„æœç´¢åŒ…\n",
    "            try:\n",
    "                from ddgs import DDGS\n",
    "            except ImportError:\n",
    "                from duckduckgo_search import DDGS\n",
    "            \n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(keywords=term, region=\"cn-zh\", max_results=max_results_per_term))\n",
    "                \n",
    "                for result in results:\n",
    "                    if 'body' in result:\n",
    "                        result['body'] = result['body'][:800] + \"...\"\n",
    "                    result['search_term'] = term\n",
    "                \n",
    "                all_results.extend(results)\n",
    "                print(f\"âœ… è·å¾— {len(results)} ä¸ªç»“æœ\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æœç´¢ '{term}' å¤±è´¥: {e}\")\n",
    "            # æ·»åŠ ä¸€ä¸ªé»˜è®¤ç»“æœé¿å…å®Œå…¨å¤±è´¥\n",
    "            all_results.append({\n",
    "                \"title\": f\"æœç´¢å¤±è´¥: {term}\",\n",
    "                \"body\": f\"æ— æ³•è·å–å…³äº'{term}'çš„æœç´¢ç»“æœ\",\n",
    "                \"href\": \"\",\n",
    "                \"search_term\": term\n",
    "            })\n",
    "    \n",
    "    print(f\"ğŸ“Š æ€»å…±è·å¾— {len(all_results)} ä¸ªæœç´¢ç»“æœ\")\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def generate_individual_industry_charts(industry, data_dict):\n",
    "    \"\"\"ç”Ÿæˆè¡Œä¸šç›¸å…³çš„ç‹¬ç«‹å›¾è¡¨æ–‡ä»¶ - ä¿®å¤æ–‡ä»¶è·¯å¾„å’Œå­˜åœ¨æ€§æ£€æŸ¥\"\"\"\n",
    "    chart_files = []\n",
    "    \n",
    "    try:\n",
    "        # è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        \n",
    "        # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„\n",
    "        import os\n",
    "        current_dir = os.getcwd()\n",
    "        \n",
    "        # 1. è¡Œä¸šè§„æ¨¡å˜åŠ¨å›¾\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "        years = list(range(2020, 2024))\n",
    "        market_size = [100, 120, 145, 170]  # æ¨¡æ‹Ÿæ•°æ®\n",
    "        ax1.plot(years, market_size, marker='o', linewidth=3, markersize=10, color='#1f77b4')\n",
    "        ax1.set_title('Industry Market Size Trend', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax1.set_xlabel('Year', fontsize=12)\n",
    "        ax1.set_ylabel('Market Size (Billion Yuan)', fontsize=12)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim(80, 200)\n",
    "        \n",
    "        # æ·»åŠ æ•°æ®æ ‡ç­¾\n",
    "        for i, v in enumerate(market_size):\n",
    "            ax1.annotate(f'{v}B', (years[i], v), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        chart1_file = os.path.join(current_dir, f'{industry}_market_size_trend.png')\n",
    "        plt.savefig(chart1_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close(fig1)\n",
    "        if os.path.exists(chart1_file):\n",
    "            chart_files.append(chart1_file)\n",
    "            print(f\"âœ… å›¾è¡¨1ç”ŸæˆæˆåŠŸ: {chart1_file}\")\n",
    "        \n",
    "        # 2. ç«äº‰æ ¼å±€åˆ†æ\n",
    "        fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "        companies = ['Company A', 'Company B', 'Company C', 'Others']\n",
    "        market_share = [30, 25, 20, 25]\n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "        \n",
    "        wedges, texts, autotexts = ax2.pie(market_share, labels=companies, autopct='%1.1f%%', \n",
    "                                          colors=colors, startangle=90, textprops={'fontsize': 12})\n",
    "        ax2.set_title('Market Competition Structure', fontsize=16, fontweight='bold', pad=20)\n",
    "        \n",
    "        # ç¾åŒ–é¥¼å›¾\n",
    "        for autotext in autotexts:\n",
    "            autotext.set_color('white')\n",
    "            autotext.set_fontweight('bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        chart2_file = os.path.join(current_dir, f'{industry}_competition_structure.png')\n",
    "        plt.savefig(chart2_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close(fig2)\n",
    "        if os.path.exists(chart2_file):\n",
    "            chart_files.append(chart2_file)\n",
    "            print(f\"âœ… å›¾è¡¨2ç”ŸæˆæˆåŠŸ: {chart2_file}\")\n",
    "        \n",
    "        # 3. äº§ä¸šé“¾ä¸Šä¸‹æ¸¸åˆ†æ\n",
    "        fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "        categories = ['Upstream', 'Midstream', 'Downstream']\n",
    "        data_2022 = [25, 45, 30]\n",
    "        data_2023 = [22, 48, 30]\n",
    "        data_2024 = [20, 50, 30]\n",
    "        \n",
    "        x = np.arange(len(categories))\n",
    "        width = 0.25\n",
    "        \n",
    "        bars1 = ax3.bar(x - width, data_2022, width, label='2022', color='#FF9999', alpha=0.8)\n",
    "        bars2 = ax3.bar(x, data_2023, width, label='2023', color='#66B2FF', alpha=0.8)\n",
    "        bars3 = ax3.bar(x + width, data_2024, width, label='2024', color='#99FF99', alpha=0.8)\n",
    "        \n",
    "        ax3.set_title('Industry Chain Structure Analysis', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax3.set_xlabel('Industry Chain Position', fontsize=12)\n",
    "        ax3.set_ylabel('Market Share (%)', fontsize=12)\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(categories)\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "        for bars in [bars1, bars2, bars3]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax3.annotate(f'{height}%', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        chart3_file = os.path.join(current_dir, f'{industry}_industry_chain.png')\n",
    "        plt.savefig(chart3_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close(fig3)\n",
    "        if os.path.exists(chart3_file):\n",
    "            chart_files.append(chart3_file)\n",
    "            print(f\"âœ… å›¾è¡¨3ç”ŸæˆæˆåŠŸ: {chart3_file}\")\n",
    "        \n",
    "        # 4. æœªæ¥è¶‹åŠ¿é¢„æµ‹\n",
    "        fig4, ax4 = plt.subplots(figsize=(12, 6))\n",
    "        historical_years = list(range(2020, 2024))\n",
    "        future_years = list(range(2024, 2028))\n",
    "        all_years = historical_years + future_years\n",
    "        \n",
    "        historical_data = [100, 120, 145, 170]\n",
    "        predicted_data = [200, 240, 280, 320]\n",
    "        \n",
    "        ax4.plot(historical_years, historical_data, 'o-', label='Historical Data', \n",
    "                linewidth=3, markersize=8, color='#1f77b4')\n",
    "        ax4.plot(future_years, predicted_data, 's--', label='Predicted Data', \n",
    "                linewidth=3, markersize=8, color='#ff7f0e', alpha=0.7)\n",
    "        \n",
    "        ax4.set_title('Industry Development Trend Forecast', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax4.set_xlabel('Year', fontsize=12)\n",
    "        ax4.set_ylabel('Market Size (Billion Yuan)', fontsize=12)\n",
    "        ax4.legend(fontsize=12)\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # å¡«å……é¢„æµ‹åŒºåŸŸ\n",
    "        ax4.fill_between(future_years, predicted_data, alpha=0.2, color='#ff7f0e')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        chart4_file = os.path.join(current_dir, f'{industry}_trend_forecast.png')\n",
    "        plt.savefig(chart4_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close(fig4)\n",
    "        if os.path.exists(chart4_file):\n",
    "            chart_files.append(chart4_file)\n",
    "            print(f\"âœ… å›¾è¡¨4ç”ŸæˆæˆåŠŸ: {chart4_file}\")\n",
    "        \n",
    "        print(f\"âœ… æ€»å…±ç”Ÿæˆäº† {len(chart_files)} ä¸ªå›¾è¡¨æ–‡ä»¶\")\n",
    "        return chart_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "def bulletproof_call_llm(prompt: str) -> str:\n",
    "    \"\"\"å®Œå…¨é˜²é”™çš„LLMè°ƒç”¨å‡½æ•°\"\"\"\n",
    "    max_length = 70000\n",
    "    \n",
    "    try:\n",
    "        if len(prompt) > max_length:\n",
    "            print(f\"è¾“å…¥è¿‡é•¿ ({len(prompt)} å­—ç¬¦)ï¼Œæ­£åœ¨æˆªæ–­...\")\n",
    "            prompt = prompt[:max_length]\n",
    "            last_period = prompt.rfind('ã€‚')\n",
    "            if last_period > max_length * 0.8:\n",
    "                prompt = prompt[:last_period + 1]\n",
    "            print(f\"æˆªæ–­åé•¿åº¦: {len(prompt)} å­—ç¬¦\")\n",
    "        \n",
    "        client = openai.OpenAI(\n",
    "            api_key=os.getenv('OPENAI_API_KEY'),\n",
    "            base_url=os.getenv('OPENAI_BASE_URL')\n",
    "        )\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=os.getenv('OPENAI_MODEL', 'deepseek-v3-250324'),\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=16384,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content\n",
    "        return result.strip() if result else \"ç”Ÿæˆå¤±è´¥\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"APIè°ƒç”¨å¤±è´¥: {e}\")\n",
    "        return \"APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å“åº”\"\n",
    "\n",
    "\n",
    "def bulletproof_search_web(term: str):\n",
    "    \"\"\"å®Œå…¨é˜²é”™çš„æœç´¢å‡½æ•°\"\"\"\n",
    "    try:\n",
    "        from duckduckgo_search import DDGS\n",
    "        with DDGS() as ddgs:\n",
    "            results = list(ddgs.text(keywords=term, region=\"cn-zh\", max_results=3))\n",
    "            for result in results:\n",
    "                if 'body' in result:\n",
    "                    result['body'] = result['body'][:500] + \"...\"\n",
    "            return results[:3]\n",
    "    except Exception as e:\n",
    "        print(f\"æœç´¢å¤±è´¥: {e}\")\n",
    "        return [{\"title\": \"æœç´¢å¤±è´¥\", \"body\": \"æ— æ³•è·å–æœç´¢ç»“æœ\", \"href\": \"\"}]\n",
    "\n",
    "def generate_smart_search_terms(industry, search_focus):\n",
    "    \"\"\"ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½æœç´¢å…³é”®è¯\"\"\"\n",
    "    try:\n",
    "        prompt = f\"\"\"\n",
    "ä¸º{industry}è¡Œä¸šç ”ç©¶ç”Ÿæˆæœ€æœ‰æ•ˆçš„æœç´¢å…³é”®è¯ï¼Œé‡ç‚¹å…³æ³¨{search_focus}ã€‚\n",
    "\n",
    "è¯·ç”Ÿæˆ5ä¸ªç²¾ç¡®çš„ä¸­æ–‡æœç´¢å…³é”®è¯ï¼Œæ¯ä¸ªå…³é”®è¯åº”è¯¥ï¼š\n",
    "1. åŒ…å«è¡Œä¸šæ ¸å¿ƒæœ¯è¯­\n",
    "2. é’ˆå¯¹{search_focus}çš„å…·ä½“å†…å®¹\n",
    "3. é€‚åˆåœ¨ä¸­æ–‡æœç´¢å¼•æ“ä¸­ä½¿ç”¨\n",
    "4. èƒ½å¤Ÿè·å¾—æƒå¨ã€ä¸“ä¸šçš„æœç´¢ç»“æœ\n",
    "\n",
    "è¡Œä¸š: {industry}\n",
    "æœç´¢é‡ç‚¹: {search_focus}\n",
    "\n",
    "è¯·ç›´æ¥è¿”å›5ä¸ªæœç´¢å…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦å…¶ä»–è¯´æ˜ï¼š\n",
    "\"\"\"\n",
    "        \n",
    "        response = bulletproof_call_llm(prompt)\n",
    "        keywords = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "        \n",
    "        # ç¡®ä¿è‡³å°‘æœ‰ä¸€äº›åŸºç¡€å…³é”®è¯\n",
    "        if not keywords:\n",
    "            if 'ç”Ÿå‘½å‘¨æœŸ' in search_focus:\n",
    "                keywords = [\n",
    "                    f\"{industry}å¸‚åœºè§„æ¨¡\",\n",
    "                    f\"{industry}å‘å±•ç°çŠ¶\",\n",
    "                    f\"{industry}å¢é•¿è¶‹åŠ¿\",\n",
    "                    f\"{industry}è¡Œä¸šæŠ¥å‘Š\",\n",
    "                    f\"{industry}å‘å±•é˜¶æ®µ\"\n",
    "                ]\n",
    "            elif 'äº§ä¸šé“¾' in search_focus or 'ç»“æ„' in search_focus:\n",
    "                keywords = [\n",
    "                    f\"{industry}äº§ä¸šé“¾\",\n",
    "                    f\"{industry}ç«äº‰æ ¼å±€\",\n",
    "                    f\"{industry}å¸‚åœºç»“æ„\",\n",
    "                    f\"{industry}ä¸»è¦ä¼ä¸š\",\n",
    "                    f\"{industry}ä¸Šä¸‹æ¸¸\"\n",
    "                ]\n",
    "            else:\n",
    "                keywords = [\n",
    "                    f\"{industry}å‘å±•è¶‹åŠ¿\",\n",
    "                    f\"{industry}æ”¿ç­–å½±å“\",\n",
    "                    f\"{industry}æŠ€æœ¯åˆ›æ–°\",\n",
    "                    f\"{industry}å¸‚åœºå‰æ™¯\",\n",
    "                    f\"{industry}æŠ•èµ„æœºä¼š\"\n",
    "                ]\n",
    "        \n",
    "        return keywords[:5]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ç”Ÿæˆæœç´¢å…³é”®è¯å¤±è´¥: {e}\")\n",
    "        return [f\"{industry}è¡Œä¸šç ”ç©¶\", f\"{industry}å¸‚åœºåˆ†æ\", f\"{industry}å‘å±•ç°çŠ¶\"]\n",
    "\n",
    "def enhanced_search_web_multiple(terms_list, max_results_per_term=5):\n",
    "    \"\"\"å¢å¼ºçš„å¤šæ¬¡æœç´¢å‡½æ•° - ä¿®å¤æœç´¢å…³é”®è¯å¤„ç†\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # æ­£ç¡®å¤„ç†æœç´¢å…³é”®è¯åˆ—è¡¨\n",
    "    if isinstance(terms_list, str):\n",
    "        search_terms = [terms_list]\n",
    "    elif isinstance(terms_list, list):\n",
    "        search_terms = []\n",
    "        for item in terms_list:\n",
    "            if isinstance(item, str):\n",
    "                search_terms.append(item)\n",
    "            elif isinstance(item, list):\n",
    "                search_terms.extend([str(subitem) for subitem in item if subitem])\n",
    "    else:\n",
    "        search_terms = [str(terms_list)]\n",
    "    \n",
    "    print(f\"ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± {len(search_terms)} ä¸ªå…³é”®è¯\")\n",
    "    \n",
    "    for i, term in enumerate(search_terms):\n",
    "        term = str(term).strip()\n",
    "        if not term:\n",
    "            continue\n",
    "            \n",
    "        print(f\"ğŸ” æœç´¢å…³é”®è¯ ({i+1}/{len(search_terms)}): {term}\")\n",
    "        \n",
    "        try:\n",
    "            # ä½¿ç”¨æ­£ç¡®çš„æœç´¢åŒ…\n",
    "            try:\n",
    "                from ddgs import DDGS\n",
    "            except ImportError:\n",
    "                from duckduckgo_search import DDGS\n",
    "            \n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(keywords=term, region=\"cn-zh\", max_results=max_results_per_term))\n",
    "                \n",
    "                for result in results:\n",
    "                    if 'body' in result:\n",
    "                        result['body'] = result['body'][:800] + \"...\"\n",
    "                    result['search_term'] = term\n",
    "                \n",
    "                all_results.extend(results)\n",
    "                print(f\"âœ… è·å¾— {len(results)} ä¸ªç»“æœ\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æœç´¢ '{term}' å¤±è´¥: {e}\")\n",
    "            # æ·»åŠ ä¸€ä¸ªé»˜è®¤ç»“æœé¿å…å®Œå…¨å¤±è´¥\n",
    "            all_results.append({\n",
    "                \"title\": f\"æœç´¢å¤±è´¥: {term}\",\n",
    "                \"body\": f\"æ— æ³•è·å–å…³äº'{term}'çš„æœç´¢ç»“æœ\",\n",
    "                \"href\": \"\",\n",
    "                \"search_term\": term\n",
    "            })\n",
    "    \n",
    "    print(f\"ğŸ“Š æ€»å…±è·å¾— {len(all_results)} ä¸ªæœç´¢ç»“æœ\")\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def generate_individual_industry_charts(industry, data_dict):\n",
    "    \"\"\"ç”Ÿæˆè¡Œä¸šç›¸å…³çš„ç‹¬ç«‹å›¾è¡¨æ–‡ä»¶ - ä¿®å¤æ–‡ä»¶è·¯å¾„å’Œå­˜åœ¨æ€§æ£€æŸ¥\"\"\"\n",
    "    chart_files = []\n",
    "    \n",
    "    try:\n",
    "        # è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        \n",
    "        # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„\n",
    "        import os\n",
    "        current_dir = os.getcwd()\n",
    "        \n",
    "        # 1. è¡Œä¸šè§„æ¨¡å˜åŠ¨å›¾\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "        years = list(range(2020, 2024))\n",
    "        market_size = [100, 120, 145, 170]  # æ¨¡æ‹Ÿæ•°æ®\n",
    "        ax1.plot(years, market_size, marker='o', linewidth=3, markersize=10, color='#1f77b4')\n",
    "        ax1.set_title('Industry Market Size Trend', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax1.set_xlabel('Year', fontsize=12)\n",
    "        ax1.set_ylabel('Market Size (Billion Yuan)', fontsize=12)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim(80, 200)\n",
    "        \n",
    "        # æ·»åŠ æ•°æ®æ ‡ç­¾\n",
    "        for i, v in enumerate(market_size):\n",
    "            ax1.annotate(f'{v}B', (years[i], v), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        chart1_file = os.path.join(current_dir, f'{industry}_market_size_trend.png')\n",
    "        plt.savefig(chart1_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close(fig1)\n",
    "        if os.path.exists(chart1_file):\n",
    "            chart_files.append(chart1_file)\n",
    "            print(f\"âœ… å›¾è¡¨1ç”ŸæˆæˆåŠŸ: {chart1_file}\")\n",
    "        \n",
    "        # 2. ç«äº‰æ ¼å±€åˆ†æ\n",
    "        fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "        companies = ['Company A', 'Company B', 'Company C', 'Others']\n",
    "        market_share = [30, 25, 20, 25]\n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "        \n",
    "        wedges, texts, autotexts = ax2.pie(market_share, labels=companies, autopct='%1.1f%%', \n",
    "                                          colors=colors, startangle=90, textprops={'fontsize': 12})\n",
    "        ax2.set_title('Market Competition Structure', fontsize=16, fontweight='bold', pad=20)\n",
    "        \n",
    "        # ç¾åŒ–é¥¼å›¾\n",
    "        for autotext in autotexts:\n",
    "            autotext.set_color('white')\n",
    "            autotext.set_fontweight('bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        chart2_file = os.path.join(current_dir, f'{industry}_competition_structure.png')\n",
    "        plt.savefig(chart2_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close(fig2)\n",
    "        if os.path.exists(chart2_file):\n",
    "            chart_files.append(chart2_file)\n",
    "            print(f\"âœ… å›¾è¡¨2ç”ŸæˆæˆåŠŸ: {chart2_file}\")\n",
    "        \n",
    "        # 3. äº§ä¸šé“¾ä¸Šä¸‹æ¸¸åˆ†æ\n",
    "        fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "        categories = ['Upstream', 'Midstream', 'Downstream']\n",
    "        data_2022 = [25, 45, 30]\n",
    "        data_2023 = [22, 48, 30]\n",
    "        data_2024 = [20, 50, 30]\n",
    "        \n",
    "        x = np.arange(len(categories))\n",
    "        width = 0.25\n",
    "        \n",
    "        bars1 = ax3.bar(x - width, data_2022, width, label='2022', color='#FF9999', alpha=0.8)\n",
    "        bars2 = ax3.bar(x, data_2023, width, label='2023', color='#66B2FF', alpha=0.8)\n",
    "        bars3 = ax3.bar(x + width, data_2024, width, label='2024', color='#99FF99', alpha=0.8)\n",
    "        \n",
    "        ax3.set_title('Industry Chain Structure Analysis', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax3.set_xlabel('Industry Chain Position', fontsize=12)\n",
    "        ax3.set_ylabel('Market Share (%)', fontsize=12)\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(categories)\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "        for bars in [bars1, bars2, bars3]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax3.annotate(f'{height}%', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        chart3_file = os.path.join(current_dir, f'{industry}_industry_chain.png')\n",
    "        plt.savefig(chart3_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close(fig3)\n",
    "        if os.path.exists(chart3_file):\n",
    "            chart_files.append(chart3_file)\n",
    "            print(f\"âœ… å›¾è¡¨3ç”ŸæˆæˆåŠŸ: {chart3_file}\")\n",
    "        \n",
    "        # 4. æœªæ¥è¶‹åŠ¿é¢„æµ‹\n",
    "        fig4, ax4 = plt.subplots(figsize=(12, 6))\n",
    "        historical_years = list(range(2020, 2024))\n",
    "        future_years = list(range(2024, 2028))\n",
    "        all_years = historical_years + future_years\n",
    "        \n",
    "        historical_data = [100, 120, 145, 170]\n",
    "        predicted_data = [200, 240, 280, 320]\n",
    "        \n",
    "        ax4.plot(historical_years, historical_data, 'o-', label='Historical Data', \n",
    "                linewidth=3, markersize=8, color='#1f77b4')\n",
    "        ax4.plot(future_years, predicted_data, 's--', label='Predicted Data', \n",
    "                linewidth=3, markersize=8, color='#ff7f0e', alpha=0.7)\n",
    "        \n",
    "        ax4.set_title('Industry Development Trend Forecast', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax4.set_xlabel('Year', fontsize=12)\n",
    "        ax4.set_ylabel('Market Size (Billion Yuan)', fontsize=12)\n",
    "        ax4.legend(fontsize=12)\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # å¡«å……é¢„æµ‹åŒºåŸŸ\n",
    "        ax4.fill_between(future_years, predicted_data, alpha=0.2, color='#ff7f0e')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        chart4_file = os.path.join(current_dir, f'{industry}_trend_forecast.png')\n",
    "        plt.savefig(chart4_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close(fig4)\n",
    "        if os.path.exists(chart4_file):\n",
    "            chart_files.append(chart4_file)\n",
    "            print(f\"âœ… å›¾è¡¨4ç”ŸæˆæˆåŠŸ: {chart4_file}\")\n",
    "        \n",
    "        print(f\"âœ… æ€»å…±ç”Ÿæˆäº† {len(chart_files)} ä¸ªå›¾è¡¨æ–‡ä»¶\")\n",
    "        return chart_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "def enhanced_industry_exec(self, inputs):\n",
    "    \"\"\"å¢å¼ºçš„è¡Œä¸šç ”ç©¶å†³ç­–å‡½æ•° - æ›´ä¸¥æ ¼çš„è¦æ±‚å’Œæ›´å¤šæœç´¢\"\"\"\n",
    "    industry, existing_info = inputs\n",
    "    \n",
    "    # æ·»åŠ æœç´¢è®¡æ•°å™¨ä»¥é˜²æ­¢æ— é™å¾ªç¯\n",
    "    if not hasattr(self, 'search_count'):\n",
    "        self.search_count = 0\n",
    "    \n",
    "    # ä»å…±äº«çŠ¶æ€ä¸­è·å–å·²ç”Ÿæˆç« èŠ‚æ•°\n",
    "    generated_sections = []\n",
    "    if hasattr(self, 'shared_state') and 'generated_sections' in self.shared_state:\n",
    "        generated_sections = self.shared_state['generated_sections']\n",
    "    \n",
    "    try:\n",
    "        # åˆ†æç°æœ‰ä¿¡æ¯çš„å®Œæ•´æ€§ - æ›´ä¸¥æ ¼çš„æ ‡å‡†\n",
    "        info_analysis = analyze_info_completeness_strict(existing_info)\n",
    "        \n",
    "        print(f\"ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ={info_analysis['lifecycle_data']:.2f}, ç»“æ„={info_analysis['structure_data']:.2f}, è¶‹åŠ¿={info_analysis['trend_data']:.2f}\")\n",
    "        print(f\"ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°={self.search_count}, å·²ç”Ÿæˆç« èŠ‚={len(generated_sections)}\")\n",
    "        \n",
    "        # å¢åŠ æœç´¢æ¬¡æ•°ä¸Šé™åˆ°6æ¬¡\n",
    "        if self.search_count >= 6:\n",
    "            print(f\"âš ï¸ æœç´¢æ¬¡æ•°å·²è¾¾{self.search_count}æ¬¡ï¼Œå¼ºåˆ¶è¿›å…¥ç”Ÿæˆé˜¶æ®µ\")\n",
    "            self.search_count = 0\n",
    "            return {\n",
    "                \"action\": \"generate\",\n",
    "                \"reason\": \"æœç´¢æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œä½¿ç”¨ç°æœ‰ä¿¡æ¯ç”ŸæˆæŠ¥å‘Š\",\n",
    "                \"section\": {\n",
    "                    \"name\": \"è¡Œä¸šç”Ÿå‘½å‘¨æœŸä¸ç»“æ„è§£è¯»\",\n",
    "                    \"focus\": \"åŸºäºç°æœ‰ä¿¡æ¯çš„è¡Œä¸šå‘å±•é˜¶æ®µã€å¸‚åœºé›†ä¸­åº¦ã€äº§ä¸šé“¾åˆ†æ\"\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦å·²ç»ç”Ÿæˆäº†è¶³å¤Ÿçš„ç« èŠ‚\n",
    "        if len(generated_sections) >= 4:\n",
    "            print(\"âœ… æ‰€æœ‰ç« èŠ‚å·²ç”Ÿæˆå®Œæˆï¼Œè¿›å…¥å®Œæ•´æŠ¥å‘Šæ•´åˆé˜¶æ®µ\")\n",
    "            return {\n",
    "                \"action\": \"complete\",\n",
    "                \"reason\": \"æ‰€æœ‰å¿…è¦ç« èŠ‚å·²ç”Ÿæˆï¼Œå¼€å§‹æ•´åˆå®Œæ•´ç ”æŠ¥\"\n",
    "            }\n",
    "        \n",
    "        # æ›´ä¸¥æ ¼çš„ä¿¡æ¯å®Œæ•´æ€§è¦æ±‚\n",
    "        total_info_score = (info_analysis['lifecycle_data'] + \n",
    "                           info_analysis['structure_data'] + \n",
    "                           info_analysis['trend_data']) / 3\n",
    "        \n",
    "        # æé«˜ä¿¡æ¯å®Œæ•´æ€§è¦æ±‚åˆ°0.7\n",
    "        if total_info_score < 0.7 and self.search_count < 6:\n",
    "            self.search_count += 1\n",
    "            \n",
    "            # æ ¹æ®ç¼ºå¤±çš„ä¿¡æ¯ç±»å‹é€‰æ‹©æœç´¢ç­–ç•¥ - ä½¿ç”¨æ™ºèƒ½å…³é”®è¯ç”Ÿæˆ\n",
    "            if info_analysis['lifecycle_data'] < 0.7:\n",
    "                search_focus = \"è¡Œä¸šç”Ÿå‘½å‘¨æœŸæ•°æ®\"\n",
    "                search_terms = generate_smart_search_terms(industry, search_focus)\n",
    "            elif info_analysis['structure_data'] < 0.7:\n",
    "                search_focus = \"äº§ä¸šé“¾ç»“æ„æ•°æ®\"\n",
    "                search_terms = generate_smart_search_terms(industry, search_focus)\n",
    "            else:\n",
    "                search_focus = \"è¶‹åŠ¿åˆ†ææ•°æ®\"\n",
    "                search_terms = generate_smart_search_terms(industry, search_focus)\n",
    "            \n",
    "            print(f\"ğŸ¯ æ™ºèƒ½ç”Ÿæˆçš„æœç´¢å…³é”®è¯: {search_terms}\")\n",
    "            \n",
    "            return {\n",
    "                \"action\": \"search\",\n",
    "                \"reason\": f\"ä¸¥æ ¼æ ‡å‡†ä¸‹ç¼ºä¹{search_focus} (ç¬¬{self.search_count}æ¬¡æœç´¢)\",\n",
    "                \"search_terms\": search_terms\n",
    "            }\n",
    "        \n",
    "        # å¦‚æœä¿¡æ¯è¶³å¤Ÿæˆ–æœç´¢æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œå¼€å§‹ç”Ÿæˆç« èŠ‚\n",
    "        else:\n",
    "            # å®šä¹‰è¦ç”Ÿæˆçš„ç« èŠ‚\n",
    "            sections_to_generate = [\n",
    "                (\"è¡Œä¸šç”Ÿå‘½å‘¨æœŸä¸ç»“æ„è§£è¯»\", \"è¡Œä¸šå‘å±•é˜¶æ®µã€å¸‚åœºé›†ä¸­åº¦ã€äº§ä¸šé“¾ä¸Šä¸‹æ¸¸åˆ†æ\"),\n",
    "                (\"ç«äº‰æ ¼å±€ä¸å¸‚åœºç»“æ„\", \"å¸‚åœºé›†ä¸­åº¦ã€ä¸»è¦ç«äº‰è€…ã€ç«äº‰ç­–ç•¥åˆ†æ\"),\n",
    "                (\"è¶‹åŠ¿åˆ†æä¸å¤–éƒ¨å˜é‡é¢„æµ‹\", \"æ”¿ç­–å½±å“ã€æŠ€æœ¯æ¼”è¿›ã€3å¹´ä»¥ä¸Šæƒ…æ™¯æ¨¡æ‹Ÿ\"),\n",
    "                (\"é£é™©è¯„ä¼°ä¸æŠ•èµ„å»ºè®®\", \"è¡Œä¸šé£é™©è¯„ä¼°ã€æŠ•èµ„æœºä¼šåˆ†æã€ç­–ç•¥å»ºè®®\")\n",
    "            ]\n",
    "            \n",
    "            # é€‰æ‹©ä¸‹ä¸€ä¸ªè¦ç”Ÿæˆçš„ç« èŠ‚\n",
    "            current_section_index = len(generated_sections)\n",
    "            if current_section_index < len(sections_to_generate):\n",
    "                section_name, section_focus = sections_to_generate[current_section_index]\n",
    "                \n",
    "                print(f\"ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬{current_section_index + 1}ä¸ªç« èŠ‚: {section_name}\")\n",
    "                \n",
    "                return {\n",
    "                    \"action\": \"generate\",\n",
    "                    \"reason\": f\"ç”Ÿæˆç¬¬{current_section_index + 1}ä¸ªæ ¸å¿ƒç« èŠ‚\",\n",
    "                    \"section\": {\n",
    "                        \"name\": section_name,\n",
    "                        \"focus\": section_focus\n",
    "                    }\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"action\": \"complete\",\n",
    "                    \"reason\": \"æ‰€æœ‰å¿…è¦ç« èŠ‚å·²ç”Ÿæˆï¼Œå¼€å§‹æ•´åˆå®Œæ•´ç ”æŠ¥\"\n",
    "                }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"å†³ç­–å¤±è´¥: {e}\")\n",
    "        if len(generated_sections) > 0:\n",
    "            return {\"action\": \"complete\", \"reason\": \"å†³ç­–å¼‚å¸¸ï¼Œä½¿ç”¨ç°æœ‰ç« èŠ‚ç”ŸæˆæŠ¥å‘Š\"}\n",
    "        else:\n",
    "            return {\n",
    "                \"action\": \"generate\", \n",
    "                \"reason\": \"å†³ç­–å¼‚å¸¸ï¼Œç”ŸæˆåŸºç¡€æŠ¥å‘Š\",\n",
    "                \"section\": {\n",
    "                    \"name\": \"è¡Œä¸šåŸºç¡€åˆ†æ\",\n",
    "                    \"focus\": \"åŸºäºç°æœ‰ä¿¡æ¯çš„è¡Œä¸šåŸºç¡€åˆ†æ\"\n",
    "                }\n",
    "            }\n",
    "\n",
    "def analyze_info_completeness_strict(existing_info):\n",
    "    \"\"\"ä¸¥æ ¼åˆ†æç°æœ‰ä¿¡æ¯çš„å®Œæ•´æ€§\"\"\"\n",
    "    if not existing_info:\n",
    "        return {\n",
    "            'lifecycle_data': 0.0,\n",
    "            'structure_data': 0.0, \n",
    "            'trend_data': 0.0,\n",
    "            'has_generated_sections': False,\n",
    "            'generated_sections': []\n",
    "        }\n",
    "    \n",
    "    # æ›´ä¸¥æ ¼çš„å…³é”®è¯æ£€æŸ¥\n",
    "    lifecycle_keywords = ['ç”Ÿå‘½å‘¨æœŸ', 'å‘å±•é˜¶æ®µ', 'æˆé•¿æœŸ', 'æˆç†ŸæœŸ', 'è¡°é€€æœŸ', 'å¹´æŠ¥', 'è´¢æŠ¥', 'è¡Œä¸š', 'å‘å±•', 'å¸‚åœº', 'è§„æ¨¡', 'å¢é•¿ç‡', 'å¸‚åœºå®¹é‡', 'é¥±å’Œåº¦']\n",
    "    structure_keywords = ['äº§ä¸šé“¾', 'ä¸Šæ¸¸', 'ä¸‹æ¸¸', 'é›†ä¸­åº¦', 'å¸‚åœºç»“æ„', 'ä¾›åº”é“¾', 'ç«äº‰', 'ä¼ä¸š', 'é¾™å¤´', 'ä»½é¢', 'å£å’', 'é—¨æ§›']\n",
    "    trend_keywords = ['è¶‹åŠ¿', 'é¢„æµ‹', 'æ”¿ç­–', 'æŠ€æœ¯', 'å‘å±•æ–¹å‘', 'æœªæ¥', 'å½±å“', 'å˜åŒ–', 'åˆ›æ–°', 'è½¬å‹', 'å‰æ™¯', 'æŠ•èµ„']\n",
    "    \n",
    "    info_text = str(existing_info).lower()\n",
    "    \n",
    "    # æ›´ä¸¥æ ¼çš„è¯„åˆ†æ ‡å‡† - éœ€è¦æ›´å¤šå…³é”®è¯åŒ¹é…\n",
    "    lifecycle_score = min(1.0, sum(1 for kw in lifecycle_keywords if kw in info_text) / 8)  # éœ€è¦8ä¸ªå…³é”®è¯\n",
    "    structure_score = min(1.0, sum(1 for kw in structure_keywords if kw in info_text) / 8)\n",
    "    trend_score = min(1.0, sum(1 for kw in trend_keywords if kw in info_text) / 8)\n",
    "    \n",
    "    # åŸºäºä¿¡æ¯é•¿åº¦çš„é¢å¤–è¯„åˆ† - æ›´ä¸¥æ ¼çš„é•¿åº¦è¦æ±‚\n",
    "    if len(info_text) > 3000:  # æé«˜é•¿åº¦è¦æ±‚\n",
    "        lifecycle_score = min(1.0, lifecycle_score + 0.2)\n",
    "        structure_score = min(1.0, structure_score + 0.2)\n",
    "        trend_score = min(1.0, trend_score + 0.2)\n",
    "    elif len(info_text) > 1500:\n",
    "        lifecycle_score = min(1.0, lifecycle_score + 0.1)\n",
    "        structure_score = min(1.0, structure_score + 0.1)\n",
    "        trend_score = min(1.0, trend_score + 0.1)\n",
    "    \n",
    "    return {\n",
    "        'lifecycle_data': lifecycle_score,\n",
    "        'structure_data': structure_score,\n",
    "        'trend_data': trend_score,\n",
    "        'has_generated_sections': 'generated_sections' in str(existing_info),\n",
    "        'generated_sections': []\n",
    "    }\n",
    "\n",
    "def extremely_strict_evaluate_report(report_content, industry):\n",
    "    \"\"\"æå…¶ä¸¥æ ¼çš„ç ”æŠ¥è¯„ä¼° - åŒ…å«CSAåˆè§„æ€§æ£€æŸ¥\"\"\"\n",
    "    try:\n",
    "        evaluation_prompt = f\"\"\"\n",
    "è¯·å¯¹ä»¥ä¸‹{industry}è¡Œä¸šç ”ç©¶æŠ¥å‘Šè¿›è¡Œæå…¶ä¸¥æ ¼çš„ä¸“ä¸šè¯„ä¼°ï¼Œé‡‡ç”¨æœ€é«˜æ ‡å‡†çš„ä¸­å›½è¯åˆ¸ä¸šåä¼šã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹åˆè§„æ€§æ£€æŸ¥ï¼š\n",
    "\n",
    "è¯„ä¼°æ ‡å‡†ï¼ˆæå…¶ä¸¥æ ¼ï¼‰ï¼š\n",
    "\n",
    "1. åˆè§„æ€§ä¸æ ¼å¼è§„èŒƒï¼ˆæƒé‡25%ï¼‰ï¼š\n",
    "   - å¿…é¡»å®Œå…¨ç¬¦åˆè¯åˆ¸ä¸šåä¼šæ‰€æœ‰æŠ«éœ²è¦æ±‚\n",
    "   - æ‰€æœ‰å¿…è¦ç« èŠ‚å¿…é¡»å®Œæ•´ä¸”å†…å®¹å……å®\n",
    "   - æ ¼å¼å¿…é¡»å®Œå…¨ç¬¦åˆä¸“ä¸šæ ‡å‡†\n",
    "   - é£é™©æç¤ºå¿…é¡»å…¨é¢è¯¦å°½\n",
    "   - è¯„åˆ†æ ‡å‡†ï¼š9-10åˆ†=å®Œç¾åˆè§„ï¼›7-8åˆ†=åŸºæœ¬åˆè§„ï¼›5-6åˆ†=éƒ¨åˆ†åˆè§„ï¼›1-4åˆ†=ä¸åˆè§„\n",
    "\n",
    "2. è®ºç‚¹-è®ºæ®é“¾å®Œæ•´æ€§ï¼ˆæƒé‡25%ï¼‰ï¼š\n",
    "   - æ¯ä¸ªæ ¸å¿ƒè§‚ç‚¹å¿…é¡»æœ‰å¼ºæœ‰åŠ›çš„å¤šé‡è®ºæ®æ”¯æ’‘\n",
    "   - è®ºæ®å¿…é¡»æ¥è‡ªæƒå¨å¯é æ¥æº\n",
    "   - é€»è¾‘æ¨ç†å¿…é¡»ä¸¥å¯†æ— æ¼æ´\n",
    "   - ç»“è®ºå¿…é¡»å®¢è§‚ä¸­æ€§ä¸”æœ‰å……åˆ†ä¾æ®\n",
    "   - è¯„åˆ†æ ‡å‡†ï¼š9-10åˆ†=é€»è¾‘å®Œç¾ï¼›7-8åˆ†=é€»è¾‘æ¸…æ™°ï¼›5-6åˆ†=é€»è¾‘ä¸€èˆ¬ï¼›1-4åˆ†=é€»è¾‘æ··ä¹±\n",
    "\n",
    "3. ç« èŠ‚è¡”æ¥æµç•…æ€§ï¼ˆæƒé‡25%ï¼‰ï¼š\n",
    "   - ç« èŠ‚é—´è¿‡æ¸¡å¿…é¡»è‡ªç„¶æµç•…\n",
    "   - å†…å®¹å±‚æ¬¡å¿…é¡»æ¸…æ™°é€’è¿›\n",
    "   - é€»è¾‘å…³ç³»å¿…é¡»æ˜ç¡®ç´§å¯†\n",
    "   - æ•´ä½“ç»“æ„å¿…é¡»åˆç†å®Œæ•´\n",
    "   - è¯„åˆ†æ ‡å‡†ï¼š9-10åˆ†=è¡”æ¥å®Œç¾ï¼›7-8åˆ†=è¡”æ¥è‰¯å¥½ï¼›5-6åˆ†=è¡”æ¥ä¸€èˆ¬ï¼›1-4åˆ†=è¡”æ¥å·®\n",
    "\n",
    "4. ä¸“ä¸šæ€§ä¸å‡†ç¡®æ€§ï¼ˆæƒé‡25%ï¼‰ï¼š\n",
    "   - æ•°æ®åˆ†æå¿…é¡»å‡†ç¡®æ— è¯¯\n",
    "   - ä¸“ä¸šæœ¯è¯­ä½¿ç”¨å¿…é¡»å®Œå…¨æ­£ç¡®\n",
    "   - åˆ†ææ–¹æ³•å¿…é¡»ç§‘å­¦ä¸¥è°¨\n",
    "   - è¡Œä¸šæ´å¯Ÿå¿…é¡»æ·±åˆ»ç‹¬åˆ°\n",
    "   - è¯„åˆ†æ ‡å‡†ï¼š9-10åˆ†=ä¸“ä¸šå®Œç¾ï¼›7-8åˆ†=ä¸“ä¸šè‰¯å¥½ï¼›5-6åˆ†=ä¸“ä¸šä¸€èˆ¬ï¼›1-4åˆ†=ä¸“ä¸šå·®\n",
    "\n",
    "æ€»åˆ†è®¡ç®—ï¼šå„ç»´åº¦å¾—åˆ†åŠ æƒå¹³å‡ï¼Œåªæœ‰æ€»åˆ†â‰¥8.5åˆ†ä¸”CSAå®Œå…¨åˆè§„æ‰ç®—ä¼˜ç§€ã€‚\n",
    "\n",
    "æŠ¥å‘Šå†…å®¹ï¼ˆå‰8000å­—ç¬¦ï¼‰ï¼š\n",
    "{report_content[:8000]}...\n",
    "\n",
    "è¯·ä»¥YAMLæ ¼å¼è¾“å‡ºæå…¶ä¸¥æ ¼çš„è¯„ä¼°ç»“æœï¼š\n",
    "```yaml\n",
    "scores:\n",
    "  compliance_format: åˆ†æ•° # 1-10ï¼Œåˆè§„æ€§ä¸æ ¼å¼è§„èŒƒ\n",
    "  logic_chain: åˆ†æ•° # 1-10ï¼Œè®ºç‚¹-è®ºæ®é“¾å®Œæ•´æ€§  \n",
    "  section_flow: åˆ†æ•° # 1-10ï¼Œç« èŠ‚è¡”æ¥æµç•…æ€§\n",
    "  professional_accuracy: åˆ†æ•° # 1-10ï¼Œä¸“ä¸šæ€§ä¸å‡†ç¡®æ€§\n",
    "total_score: æ€»åˆ† # 1-10ï¼ŒåŠ æƒå¹³å‡\n",
    "csa_compliance: true/false # æ˜¯å¦å®Œå…¨ç¬¦åˆè¯åˆ¸ä¸šåä¼šè§„å®š\n",
    "quality_level: ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬/å·® # åŸºäºæ€»åˆ†çš„è´¨é‡ç­‰çº§\n",
    "strengths:\n",
    "  - å…·ä½“ä¼˜ç‚¹1\n",
    "  - å…·ä½“ä¼˜ç‚¹2\n",
    "  - å…·ä½“ä¼˜ç‚¹3\n",
    "weaknesses:\n",
    "  - å…·ä½“ä¸è¶³1\n",
    "  - å…·ä½“ä¸è¶³2\n",
    "  - å…·ä½“ä¸è¶³3\n",
    "critical_issues:\n",
    "  - ä¸¥é‡é—®é¢˜1\n",
    "  - ä¸¥é‡é—®é¢˜2\n",
    "improvement_suggestions:\n",
    "  - è¯¦ç»†æ”¹è¿›å»ºè®®1\n",
    "  - è¯¦ç»†æ”¹è¿›å»ºè®®2\n",
    "  - è¯¦ç»†æ”¹è¿›å»ºè®®3\n",
    "```\n",
    "\n",
    "è¯·æŒ‰ç…§æœ€ä¸¥æ ¼çš„æ ‡å‡†è¿›è¡Œè¯„ä¼°ï¼Œä¸è¦ç»™å‡ºè¿‡é«˜çš„åˆ†æ•°ã€‚åªæœ‰çœŸæ­£ä¼˜ç§€çš„ç ”æŠ¥æ‰èƒ½è·å¾—8åˆ†ä»¥ä¸Šã€‚\n",
    "\"\"\"\n",
    "        \n",
    "        response = bulletproof_call_llm(evaluation_prompt)\n",
    "        yaml_str = response.split(\"```yaml\")[1].split(\"```\", 1)[0].strip()\n",
    "        evaluation = yaml.safe_load(yaml_str)\n",
    "        \n",
    "        return evaluation\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"è¯„ä¼°å¤±è´¥: {e}\")\n",
    "        return {\n",
    "            'scores': {\n",
    "                'compliance_format': 3, \n",
    "                'logic_chain': 3, \n",
    "                'section_flow': 3,\n",
    "                'professional_accuracy': 3\n",
    "            },\n",
    "            'total_score': 3,\n",
    "            'csa_compliance': False,\n",
    "            'quality_level': 'å·®',\n",
    "            'strengths': ['åŸºæœ¬ç»“æ„å­˜åœ¨'],\n",
    "            'weaknesses': ['è¯„ä¼°ç³»ç»Ÿå¼‚å¸¸', 'æ— æ³•æ­£ç¡®è¯„ä¼°'],\n",
    "            'critical_issues': ['è¯„ä¼°ç³»ç»Ÿæ•…éšœ'],\n",
    "            'improvement_suggestions': ['ä¿®å¤è¯„ä¼°ç³»ç»Ÿåé‡æ–°è¯„ä¼°']\n",
    "        }\n",
    "\n",
    "def enhanced_complete_report_post(self, shared, prep_res, exec_res):\n",
    "    \"\"\"å¢å¼ºçš„ç ”æŠ¥å®Œæˆå¤„ç† - ä¿®å¤å›¾è¡¨æ’å…¥é€»è¾‘\"\"\"\n",
    "    industry = shared.get(\"industry\", \"è¡Œä¸šç ”ç©¶\")\n",
    "    \n",
    "    # å…ˆç”Ÿæˆå›¾è¡¨æ–‡ä»¶ - åœ¨ç”ŸæˆWordæ–‡æ¡£ä¹‹å‰\n",
    "    print(\"ğŸ“Š å¼€å§‹ç”Ÿæˆå›¾è¡¨æ–‡ä»¶...\")\n",
    "    chart_files = generate_individual_industry_charts(industry, {})\n",
    "    print(f\"ğŸ“Š å›¾è¡¨ç”Ÿæˆå®Œæˆï¼Œå…± {len(chart_files)} ä¸ªæ–‡ä»¶\")\n",
    "    \n",
    "    # éªŒè¯å›¾è¡¨æ–‡ä»¶å­˜åœ¨\n",
    "    valid_chart_files = []\n",
    "    for chart_file in chart_files:\n",
    "        if os.path.exists(chart_file):\n",
    "            valid_chart_files.append(chart_file)\n",
    "            print(f\"âœ… å›¾è¡¨æ–‡ä»¶éªŒè¯é€šè¿‡: {os.path.basename(chart_file)}\")\n",
    "        else:\n",
    "            print(f\"âŒ å›¾è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {chart_file}\")\n",
    "    \n",
    "    chart_files = valid_chart_files\n",
    "    \n",
    "    # ä½¿ç”¨æå…¶ä¸¥æ ¼çš„è¯„ä¼°åŠŸèƒ½\n",
    "    evaluation = extremely_strict_evaluate_report(exec_res, industry)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æå…¶ä¸¥æ ¼çš„CSAåˆè§„æ€§ç ”æŠ¥è´¨é‡è¯„ä¼°:\")\n",
    "    print(f\"æ€»åˆ†: {evaluation['total_score']}/10\")\n",
    "    print(f\"è´¨é‡ç­‰çº§: {evaluation['quality_level']}\")\n",
    "    print(f\"åˆè§„æ€§ä¸æ ¼å¼: {evaluation['scores']['compliance_format']}/10\")\n",
    "    print(f\"è®ºç‚¹-è®ºæ®é“¾: {evaluation['scores']['logic_chain']}/10\")\n",
    "    print(f\"ç« èŠ‚è¡”æ¥: {evaluation['scores']['section_flow']}/10\")\n",
    "    print(f\"ä¸“ä¸šå‡†ç¡®æ€§: {evaluation['scores']['professional_accuracy']}/10\")\n",
    "    print(f\"CSAåˆè§„æ€§: {'âœ… å®Œå…¨ç¬¦åˆ' if evaluation['csa_compliance'] else 'âŒ ä¸ç¬¦åˆ'}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºä¸¥é‡é—®é¢˜\n",
    "    if 'critical_issues' in evaluation and evaluation['critical_issues']:\n",
    "        print(f\"âš ï¸ ä¸¥é‡é—®é¢˜: {evaluation['critical_issues']}\")\n",
    "    \n",
    "    # æå…¶ä¸¥æ ¼çš„æ”¹è¿›æ ‡å‡† - æœ€å¤š8æ¬¡æ”¹è¿›\n",
    "    max_iterations = 8\n",
    "    current_iteration = 0\n",
    "    best_report = exec_res\n",
    "    best_evaluation = evaluation\n",
    "    \n",
    "    # åªæœ‰æ€»åˆ†â‰¥8.5ä¸”CSAå®Œå…¨åˆè§„æ‰ç®—è¾¾æ ‡\n",
    "    while (not best_evaluation['csa_compliance'] or best_evaluation['total_score'] < 8.5) and current_iteration < max_iterations:\n",
    "        current_iteration += 1\n",
    "        print(f\"\\nğŸ”„ ç¬¬{current_iteration}æ¬¡æä¸¥æ ¼æ”¹è¿› (æœ€å¤š{max_iterations}æ¬¡)...\")\n",
    "        \n",
    "        improvement_prompt = f\"\"\"\n",
    "åŸºäºæå…¶ä¸¥æ ¼çš„è¯„ä¼°åé¦ˆï¼Œè¯·å½»åº•æ”¹è¿›{industry}è¡Œä¸šç ”ç©¶æŠ¥å‘Šä½¿å…¶å®Œå…¨ç¬¦åˆæœ€é«˜æ ‡å‡†çš„ä¸­å›½è¯åˆ¸ä¸šåä¼šè§„å®šï¼š\n",
    "\n",
    "åŸæŠ¥å‘Šï¼š\n",
    "{best_report}\n",
    "\n",
    "ä¸¥æ ¼è¯„ä¼°åé¦ˆï¼š\n",
    "å½“å‰å¾—åˆ†: {best_evaluation['total_score']}/10\n",
    "è´¨é‡ç­‰çº§: {best_evaluation['quality_level']}\n",
    "ä¼˜ç‚¹: {best_evaluation['strengths']}\n",
    "ä¸è¶³: {best_evaluation['weaknesses']}\n",
    "ä¸¥é‡é—®é¢˜: {best_evaluation.get('critical_issues', [])}\n",
    "è¯¦ç»†æ”¹è¿›å»ºè®®: {best_evaluation['improvement_suggestions']}\n",
    "CSAåˆè§„æ€§: {best_evaluation['csa_compliance']}\n",
    "\n",
    "è¯·å®Œå…¨é‡æ–°ç”Ÿæˆç¬¦åˆä»¥ä¸‹æœ€é«˜æ ‡å‡†çš„ç ”æŠ¥ï¼š\n",
    "\n",
    "1. å®Œç¾çš„æ ¼å¼ä¸é€»è¾‘è¦æ±‚ï¼š\n",
    "   - 100%æ»¡è¶³ã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹æ‰€æœ‰è¦æ±‚\n",
    "   - è®ºç‚¹-è®ºæ®é“¾å¿…é¡»å®Œç¾æ— ç¼º\n",
    "   - ç« èŠ‚è¡”æ¥å¿…é¡»å¤©è¡£æ— ç¼\n",
    "   - æ‰€æœ‰æŠ«éœ²ä¿¡æ¯å¿…é¡»å®Œæ•´è¯¦å°½\n",
    "\n",
    "2. å¿…è¦ç« èŠ‚çš„å®Œç¾æ‰§è¡Œï¼š\n",
    "   - æŠ•èµ„è¦ç‚¹ï¼šæ ¸å¿ƒè§‚ç‚¹æ¸…æ™°ã€æŠ•èµ„é€»è¾‘ä¸¥å¯†\n",
    "   - ç ”ç©¶æ–¹æ³•ï¼šæ–¹æ³•ç§‘å­¦ã€æ•°æ®æƒå¨\n",
    "   - åˆ†æå¸ˆå£°æ˜ï¼šå®Œå…¨åˆè§„ã€ä¿¡æ¯å®Œæ•´\n",
    "   - æ³•å¾‹å£°æ˜ï¼šæ¡æ¬¾å®Œæ•´ã€è¡¨è¿°å‡†ç¡®\n",
    "   - é£é™©æç¤ºï¼šå…¨é¢æ·±å…¥ã€å®¢è§‚ä¸­æ€§\n",
    "\n",
    "3. æœ€é«˜ä¸“ä¸šæ ‡å‡†ï¼š\n",
    "   - æ‰€æœ‰æ•°æ®å¿…é¡»å‡†ç¡®å¯é \n",
    "   - åˆ†æå¿…é¡»å®¢è§‚ä¸­æ€§ä¸”æ·±å…¥\n",
    "   - æœ¯è¯­ä½¿ç”¨å¿…é¡»å®Œå…¨è§„èŒƒ\n",
    "   - ç»“è®ºå¿…é¡»æœ‰å……åˆ†ä¾æ®\n",
    "\n",
    "ç›®æ ‡ï¼šæ€»åˆ†â‰¥8.5åˆ†ä¸”CSAå®Œå…¨åˆè§„ã€‚è¯·å½»åº•é‡å†™æ•´ä¸ªç ”æŠ¥ã€‚\n",
    "\"\"\"\n",
    "        \n",
    "        improved_report = bulletproof_call_llm(improvement_prompt)\n",
    "        \n",
    "        # é‡æ–°è¿›è¡Œä¸¥æ ¼è¯„ä¼°\n",
    "        new_evaluation = extremely_strict_evaluate_report(improved_report, industry)\n",
    "        print(f\"ğŸ“ˆ ç¬¬{current_iteration}æ¬¡æ”¹è¿›åè¯„åˆ†: {new_evaluation['total_score']}/10\")\n",
    "        print(f\"è´¨é‡ç­‰çº§: {new_evaluation['quality_level']}\")\n",
    "        print(f\"CSAåˆè§„æ€§: {'âœ… å®Œå…¨ç¬¦åˆ' if new_evaluation['csa_compliance'] else 'âŒ ä¸ç¬¦åˆ'}\")\n",
    "        \n",
    "        # ä¼˜å…ˆé€‰æ‹©CSAåˆè§„ä¸”é«˜åˆ†çš„æŠ¥å‘Š\n",
    "        if new_evaluation['csa_compliance'] and new_evaluation['total_score'] >= 8.5:\n",
    "            best_report = improved_report\n",
    "            best_evaluation = new_evaluation\n",
    "            print(f\"ğŸ‰ ç¬¬{current_iteration}æ¬¡æ”¹è¿›è¾¾åˆ°æœ€é«˜æ ‡å‡†!\")\n",
    "            break\n",
    "        elif new_evaluation['total_score'] > best_evaluation['total_score']:\n",
    "            best_report = improved_report\n",
    "            best_evaluation = new_evaluation\n",
    "            print(f\"âœ… ç¬¬{current_iteration}æ¬¡æ”¹è¿›æå‡è´¨é‡åˆ†æ•°\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ ç¬¬{current_iteration}æ¬¡æ”¹è¿›æ•ˆæœä¸æ˜æ˜¾\")\n",
    "    \n",
    "    # ä½¿ç”¨æœ€ä½³æŠ¥å‘Š\n",
    "    exec_res = best_report\n",
    "    evaluation = best_evaluation\n",
    "    \n",
    "    # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š - ä½¿ç”¨å®‰å…¨çš„æ–‡ä»¶å\n",
    "    safe_industry_name = industry.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\").replace(\"*\", \"_\").replace(\"?\", \"_\").replace('\"', \"_\").replace(\"<\", \"_\").replace(\">\", \"_\").replace(\"|\", \"_\")\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    md_filename = f\"{safe_industry_name}_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_{current_date}.md\"\n",
    "    docx_filename = f\"{safe_industry_name}_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_{current_date}.docx\"\n",
    "    \n",
    "    try:\n",
    "        # ä¿å­˜Markdownæ–‡ä»¶\n",
    "        with open(md_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(exec_res)\n",
    "        print(f\"âœ… æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥å·²ä¿å­˜: {md_filename}\")\n",
    "        \n",
    "        # ä¿å­˜Wordæ–‡æ¡£å¹¶æ’å…¥å›¾è¡¨ - ä¿®å¤æ’å…¥é€»è¾‘\n",
    "        try:\n",
    "            from docx import Document\n",
    "            from docx.shared import Inches\n",
    "            doc = Document()\n",
    "            \n",
    "            # æ·»åŠ å°é¢ä¿¡æ¯\n",
    "            doc.add_heading(f'{industry}è¡Œä¸šç ”ç©¶æŠ¥å‘Š', 0)\n",
    "            doc.add_paragraph(f'è´¨é‡ç­‰çº§: {evaluation[\"quality_level\"]}')\n",
    "            doc.add_paragraph(f'CSAåˆè§„æ€§: {\"âœ… å®Œå…¨ç¬¦åˆ\" if evaluation[\"csa_compliance\"] else \"âŒ ä¸ç¬¦åˆ\"}')\n",
    "            doc.add_paragraph(f'è¯„ä¼°æ€»åˆ†: {evaluation[\"total_score\"]}/10')\n",
    "            doc.add_paragraph(f'æ”¹è¿›æ¬¡æ•°: {current_iteration}æ¬¡')\n",
    "            doc.add_paragraph(f'ç”Ÿæˆå›¾è¡¨: {len(chart_files)}ä¸ª')\n",
    "            doc.add_paragraph('')\n",
    "            \n",
    "            # å¤„ç†æŠ¥å‘Šå†…å®¹å¹¶åœ¨é€‚å½“ä½ç½®æ’å…¥å›¾è¡¨\n",
    "            lines = exec_res.split('\\n')\n",
    "            chart_insertion_points = [\n",
    "                '## è¡Œä¸šåˆ†æ',\n",
    "                '## ç«äº‰æ ¼å±€', \n",
    "                '## äº§ä¸šé“¾',\n",
    "                '## è¶‹åŠ¿',\n",
    "                '## é¢„æµ‹'\n",
    "            ]\n",
    "            chart_index = 0\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line.startswith('# '):\n",
    "                    doc.add_heading(line[2:], level=1)\n",
    "                elif line.startswith('## '):\n",
    "                    heading_text = line[3:]\n",
    "                    doc.add_heading(heading_text, level=2)\n",
    "                    \n",
    "                    # åœ¨ç‰¹å®šç« èŠ‚åæ’å…¥å›¾è¡¨\n",
    "                    if chart_index < len(chart_files):\n",
    "                        should_insert = any(keyword in heading_text for keyword in chart_insertion_points)\n",
    "                        if should_insert:\n",
    "                            try:\n",
    "                                doc.add_paragraph(f'å›¾è¡¨ {chart_index + 1}ï¼š')\n",
    "                                doc.add_picture(chart_files[chart_index], width=Inches(6))\n",
    "                                print(f\"âœ… å›¾è¡¨ {chart_index + 1} æ’å…¥æˆåŠŸ: {os.path.basename(chart_files[chart_index])}\")\n",
    "                                chart_index += 1\n",
    "                            except Exception as chart_error:\n",
    "                                print(f\"âŒ å›¾è¡¨ {chart_index + 1} æ’å…¥å¤±è´¥: {chart_error}\")\n",
    "                                doc.add_paragraph(f'[å›¾è¡¨æ–‡ä»¶æ’å…¥å¤±è´¥: {os.path.basename(chart_files[chart_index])}]')\n",
    "                                chart_index += 1\n",
    "                                \n",
    "                elif line.startswith('### '):\n",
    "                    doc.add_heading(line[4:], level=3)\n",
    "                elif line.startswith('**') and line.endswith('**') and len(line) > 4:\n",
    "                    p = doc.add_paragraph()\n",
    "                    p.add_run(line[2:-2]).bold = True\n",
    "                elif line and not line.startswith('#'):\n",
    "                    doc.add_paragraph(line)\n",
    "            \n",
    "            # æ’å…¥å‰©ä½™çš„å›¾è¡¨åˆ°é™„å½•\n",
    "            if chart_index < len(chart_files):\n",
    "                doc.add_heading('é™„å½•ï¼šè¡¥å……å›¾è¡¨', level=2)\n",
    "                for i in range(chart_index, len(chart_files)):\n",
    "                    try:\n",
    "                        doc.add_paragraph(f'å›¾è¡¨ {i + 1}ï¼š')\n",
    "                        doc.add_picture(chart_files[i], width=Inches(6))\n",
    "                        print(f\"âœ… é™„å½•å›¾è¡¨ {i + 1} æ’å…¥æˆåŠŸ\")\n",
    "                    except Exception as chart_error:\n",
    "                        print(f\"âŒ é™„å½•å›¾è¡¨ {i + 1} æ’å…¥å¤±è´¥: {chart_error}\")\n",
    "                        doc.add_paragraph(f'[å›¾è¡¨æ–‡ä»¶æ’å…¥å¤±è´¥: {os.path.basename(chart_files[i])}]')\n",
    "            \n",
    "            doc.save(docx_filename)\n",
    "            print(f\"âœ… Wordæ–‡æ¡£å·²ä¿å­˜å¹¶æ’å…¥ {len(chart_files)} ä¸ªå›¾è¡¨: {docx_filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Wordæ–‡æ¡£ä¿å­˜å¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        # ä¿å­˜è¯¦ç»†è¯„ä¼°æŠ¥å‘Š\n",
    "        eval_filename = f\"{safe_industry_name}_æä¸¥æ ¼CSAåˆè§„è¯„ä¼°_{current_date}.yaml\"\n",
    "        evaluation_with_meta = {\n",
    "            **evaluation,\n",
    "            'improvement_iterations': current_iteration,\n",
    "            'max_iterations': max_iterations,\n",
    "            'final_quality_achieved': evaluation['quality_level'],\n",
    "            'strict_grading_system': True,\n",
    "            'minimum_passing_score': 8.5,\n",
    "            'charts_generated': len(chart_files),\n",
    "            'chart_files': [os.path.basename(f) for f in chart_files]\n",
    "        }\n",
    "        with open(eval_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            yaml.dump(evaluation_with_meta, f, allow_unicode=True)\n",
    "        print(f\"âœ… è¯¦ç»†è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {eval_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    shared[\"report\"] = exec_res\n",
    "    shared[\"evaluation\"] = evaluation\n",
    "    shared[\"improvement_iterations\"] = current_iteration\n",
    "    shared[\"filename\"] = md_filename\n",
    "    shared[\"chart_files\"] = chart_files\n",
    "    \n",
    "    return exec_res\n",
    "\n",
    "def enhanced_generate_section_exec(self, inputs):\n",
    "    \"\"\"å¢å¼ºçš„ç« èŠ‚ç”Ÿæˆæ‰§è¡Œå‡½æ•°\"\"\"\n",
    "    try:\n",
    "        section_info = inputs\n",
    "        industry = self.shared_state.get(\"industry\", \"è¡Œä¸šç ”ç©¶\") if hasattr(self, 'shared_state') else \"è¡Œä¸šç ”ç©¶\"\n",
    "        \n",
    "        # è·å–æ‰€æœ‰ç°æœ‰ä¿¡æ¯\n",
    "        existing_info = self.shared_state.get(\"existing_info\", \"\") if hasattr(self, 'shared_state') else \"\"\n",
    "        \n",
    "        # ç”Ÿæˆç« èŠ‚å†…å®¹\n",
    "        section_prompt = f\"\"\"\n",
    "è¯·ä¸º{industry}è¡Œä¸šç ”ç©¶æŠ¥å‘Šç”Ÿæˆä»¥ä¸‹ç« èŠ‚ï¼š\n",
    "\n",
    "ç« èŠ‚åç§°: {section_info.get('name', 'è¡Œä¸šåˆ†æ')}\n",
    "ç« èŠ‚é‡ç‚¹: {section_info.get('focus', 'åŸºç¡€åˆ†æ')}\n",
    "\n",
    "ç°æœ‰ä¿¡æ¯å‚è€ƒ:\n",
    "{existing_info}\n",
    "\n",
    "è¯·ç”Ÿæˆä¸“ä¸šã€è¯¦ç»†ã€ç¬¦åˆè¯åˆ¸ä¸šåä¼šè§„å®šçš„ç« èŠ‚å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š\n",
    "1. æ¸…æ™°çš„ç« èŠ‚ç»“æ„\n",
    "2. è¯¦ç»†çš„åˆ†æå†…å®¹\n",
    "3. æ•°æ®æ”¯æ’‘çš„è®ºè¯\n",
    "4. å®¢è§‚ä¸­æ€§çš„ç»“è®º\n",
    "\n",
    "è¦æ±‚ï¼š\n",
    "- å†…å®¹ä¸“ä¸šä¸”æ·±å…¥\n",
    "- ç»“æ„æ¸…æ™°æœ‰å±‚æ¬¡\n",
    "- æ•°æ®åˆ†æå‡†ç¡®\n",
    "- ç¬¦åˆç ”æŠ¥æ ¼å¼è§„èŒƒ\n",
    "\"\"\"\n",
    "        \n",
    "        section_content = bulletproof_call_llm(section_prompt)\n",
    "        \n",
    "        # æ›´æ–°å…±äº«çŠ¶æ€\n",
    "        if hasattr(self, 'shared_state'):\n",
    "            if 'generated_sections' not in self.shared_state:\n",
    "                self.shared_state['generated_sections'] = []\n",
    "            self.shared_state['generated_sections'].append(section_info.get('name', 'ç« èŠ‚'))\n",
    "            \n",
    "            # ç´¯ç§¯ç”Ÿæˆçš„å†…å®¹\n",
    "            if 'existing_info' not in self.shared_state:\n",
    "                self.shared_state['existing_info'] = \"\"\n",
    "            self.shared_state['existing_info'] += f\"\\n\\n{section_content}\"\n",
    "        \n",
    "        print(f\"âœ… ç« èŠ‚ç”Ÿæˆå®Œæˆ: {section_info.get('name', 'ç« èŠ‚')}\")\n",
    "        \n",
    "        return {\n",
    "            \"action\": \"continue\",\n",
    "            \"section_content\": section_content,\n",
    "            \"section_name\": section_info.get('name', 'ç« èŠ‚')\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ç« èŠ‚ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        return {\n",
    "            \"action\": \"continue\",\n",
    "            \"section_content\": \"ç« èŠ‚ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®\",\n",
    "            \"section_name\": \"é”™è¯¯ç« èŠ‚\"\n",
    "        }\n",
    "\n",
    "def enhanced_complete_report_exec(self, inputs):\n",
    "    \"\"\"å¢å¼ºçš„å®Œæ•´æŠ¥å‘Šæ‰§è¡Œå‡½æ•°\"\"\"\n",
    "    try:\n",
    "        industry = self.shared_state.get(\"industry\", \"è¡Œä¸šç ”ç©¶\") if hasattr(self, 'shared_state') else \"è¡Œä¸šç ”ç©¶\"\n",
    "        existing_info = self.shared_state.get(\"existing_info\", \"\") if hasattr(self, 'shared_state') else \"\"\n",
    "        generated_sections = self.shared_state.get(\"generated_sections\", []) if hasattr(self, 'shared_state') else []\n",
    "        \n",
    "        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š\n",
    "        complete_report_prompt = f\"\"\"\n",
    "è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå®Œæ•´çš„{industry}è¡Œä¸šç ”ç©¶æŠ¥å‘Šï¼Œä¸¥æ ¼ç¬¦åˆä¸­å›½è¯åˆ¸ä¸šåä¼šã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹ï¼š\n",
    "\n",
    "å·²ç”Ÿæˆç« èŠ‚: {generated_sections}\n",
    "\n",
    "ç°æœ‰ä¿¡æ¯:\n",
    "{existing_info}\n",
    "\n",
    "è¯·ç”Ÿæˆå®Œæ•´çš„ä¸“ä¸šç ”æŠ¥ï¼ŒåŒ…æ‹¬ï¼š\n",
    "1. æŠ¥å‘Šæ‘˜è¦\n",
    "2. æŠ•èµ„è¦ç‚¹\n",
    "3. è¡Œä¸šåˆ†æ\n",
    "4. ç«äº‰æ ¼å±€\n",
    "5. é£é™©æç¤º\n",
    "6. æŠ•èµ„å»ºè®®\n",
    "7. åˆ†æå¸ˆå£°æ˜\n",
    "8. æ³•å¾‹å£°æ˜\n",
    "\n",
    "è¦æ±‚ï¼š\n",
    "- å®Œå…¨ç¬¦åˆè¯åˆ¸ä¸šåä¼šè§„å®š\n",
    "- å†…å®¹ä¸“ä¸šä¸”å®¢è§‚\n",
    "- ç»“æ„æ¸…æ™°å®Œæ•´\n",
    "- åŒ…å«å¿…è¦çš„æŠ«éœ²ä¿¡æ¯\n",
    "- é£é™©æç¤ºå……åˆ†\n",
    "\"\"\"\n",
    "        \n",
    "        complete_report = bulletproof_call_llm(complete_report_prompt)\n",
    "        \n",
    "        print(f\"âœ… å®Œæ•´æŠ¥å‘Šç”Ÿæˆå®Œæˆ\")\n",
    "        \n",
    "        return complete_report\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"å®Œæ•´æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        return \"å®Œæ•´æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®\"\n",
    "\n",
    "# åº”ç”¨æ‰€æœ‰è¡¥ä¸\n",
    "industry_workflow.call_llm = bulletproof_call_llm\n",
    "industry_workflow.search_web = enhanced_search_web_multiple\n",
    "industry_workflow.IndustryResearchFlow.exec = enhanced_industry_exec\n",
    "industry_workflow.GenerateSection.exec = enhanced_generate_section_exec\n",
    "industry_workflow.CompleteReport.exec = enhanced_complete_report_exec\n",
    "industry_workflow.CompleteReport.post = enhanced_complete_report_post\n",
    "\n",
    "print(\"ğŸš€ æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥ç”Ÿæˆç³»ç»Ÿå·²å¯ç”¨:\")\n",
    "print(\"  âœ“ ä¸¥æ ¼éµå¾ªã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹\")\n",
    "print(\"  âœ“ æå…¶ä¸¥æ ¼çš„è¯„åˆ†æ ‡å‡†ï¼ˆâ‰¥8.5åˆ†æ‰ç®—ä¼˜ç§€ï¼‰\")\n",
    "print(\"  âœ“ æ™ºèƒ½æœç´¢å…³é”®è¯ç”Ÿæˆï¼ˆLLMé©±åŠ¨ï¼‰\")\n",
    "print(\"  âœ“ ä¿®å¤äº†ä¸­æ–‡å…³é”®è¯æœç´¢é—®é¢˜\")\n",
    "print(\"  âœ“ å¢å¼ºçš„å¤šæ¬¡æœç´¢ï¼ˆæœ€å¤š6æ¬¡ï¼Œæ¯æ¬¡æ›´å¤šç»“æœï¼‰\")\n",
    "print(\"  âœ“ ç‹¬ç«‹å›¾è¡¨ç”Ÿæˆå¹¶æ’å…¥Wordæ–‡æ¡£ - ä¿®å¤æ’å…¥é€»è¾‘\")\n",
    "print(\"  âœ“ ä¸­æ–‡å­—ä½“é—®é¢˜å·²ä¿®å¤\")\n",
    "print(\"  âœ“ æœ€å¤š8æ¬¡æ”¹è¿›è¿­ä»£\")\n",
    "print(\"  âœ“ å®Œæ•´çš„åˆè§„æ€§éªŒè¯ä½“ç³»\")\n",
    "print(\"  âœ“ å›¾è¡¨æ–‡ä»¶å­˜åœ¨æ€§éªŒè¯\")\n",
    "print(\"  âœ“ æ™ºèƒ½å›¾è¡¨æ’å…¥ä½ç½®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba1f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ å¯åŠ¨ç¬¦åˆè¯åˆ¸ä¸šåä¼šè§„å®šçš„ç ”æŠ¥ç”Ÿæˆç³»ç»Ÿ...\n",
      "ğŸ“œ ä¸¥æ ¼éµå¾ªã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹\n",
      "ğŸ’¡ æ™ºèƒ½åˆè§„æ€§éªŒè¯ï¼šæœ€å¤š8æ¬¡æ”¹è¿›è¿­ä»£\n",
      "ğŸ“Š æä¸¥æ ¼è¯„åˆ†æ ‡å‡†ï¼šâ‰¥8.5åˆ†æ‰ç®—ä¼˜ç§€\n",
      "ğŸ” å¢å¼ºæœç´¢èƒ½åŠ›ï¼šæœ€å¤š6æ¬¡æœç´¢ï¼Œæ¯æ¬¡æ›´å¤šç»“æœ\n",
      "ğŸ“ˆ ç‹¬ç«‹å›¾è¡¨ç”Ÿæˆï¼š4ä¸ªä¸“ä¸šå›¾è¡¨æ’å…¥Wordæ–‡æ¡£\n",
      "ğŸš€ å¼€å§‹æ‰§è¡Œç¬¦åˆCSAè§„å®šçš„ç ”æŠ¥ç”Ÿæˆå·¥ä½œæµ...\n",
      "ğŸ“Š ç›®æ ‡è¡Œä¸š: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡\n",
      "ğŸ“‹ CSAåˆè§„è¦æ±‚:\n",
      "  â€¢ ç¬¦åˆã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹\n",
      "  â€¢ è®ºç‚¹-è®ºæ®é“¾å®Œæ•´æ¸…æ™°\n",
      "  â€¢ ç« èŠ‚è¡”æ¥æµç•…è‡ªç„¶\n",
      "  â€¢ å¿…è¦æŠ«éœ²ä¿¡æ¯å®Œæ•´\n",
      "  â€¢ ä¸“ä¸šæ ¼å¼ä¸é£é™©æç¤º\n",
      "  â€¢ æ™ºèƒ½åˆè§„æ€§éªŒè¯ (æœ€å¤š8æ¬¡æ”¹è¿›)\n",
      "  â€¢ æä¸¥æ ¼è¯„åˆ†æ ‡å‡† (â‰¥8.5åˆ†)\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.00, ç»“æ„=0.00, è¶‹åŠ¿=0.00\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=0\n",
      "ğŸ¯ æ™ºèƒ½ç”Ÿæˆçš„æœç´¢å…³é”®è¯: ['æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡è¡Œä¸šç”Ÿå‘½å‘¨æœŸæ•°æ®åˆ†ææŠ¥å‘Š', 'æ™ºèƒ½é£æ§å¾ä¿¡æœåŠ¡å‘å±•é˜¶æ®µæ•°æ®ç ”ç©¶', 'å¤§æ•°æ®å¾ä¿¡è¡Œä¸šå¢é•¿è¶‹åŠ¿ç”Ÿå‘½å‘¨æœŸæ•°æ®', 'é£æ§å¾ä¿¡æœåŠ¡å¸‚åœºæˆç†Ÿåº¦æ•°æ®åˆ†æ', 'æ™ºèƒ½é£æ§è¡Œä¸šç”Ÿå‘½å‘¨æœŸç«äº‰æ ¼å±€æ•°æ®']\n",
      "\n",
      "=== å¼€å§‹ä¿¡æ¯æœç´¢é˜¶æ®µ ===\n",
      "\n",
      "æœç´¢å…³é”®è¯ (1/5): æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡è¡Œä¸šç”Ÿå‘½å‘¨æœŸæ•°æ®åˆ†ææŠ¥å‘Š\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡è¡Œä¸šç”Ÿå‘½å‘¨æœŸæ•°æ®åˆ†ææŠ¥å‘Š\n",
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n",
      "ğŸ¯ æ™ºèƒ½ç”Ÿæˆçš„æœç´¢å…³é”®è¯: ['æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡è¡Œä¸šç”Ÿå‘½å‘¨æœŸæ•°æ®åˆ†ææŠ¥å‘Š', 'æ™ºèƒ½é£æ§å¾ä¿¡æœåŠ¡å‘å±•é˜¶æ®µæ•°æ®ç ”ç©¶', 'å¤§æ•°æ®å¾ä¿¡è¡Œä¸šå¢é•¿è¶‹åŠ¿ç”Ÿå‘½å‘¨æœŸæ•°æ®', 'é£æ§å¾ä¿¡æœåŠ¡å¸‚åœºæˆç†Ÿåº¦æ•°æ®åˆ†æ', 'æ™ºèƒ½é£æ§è¡Œä¸šç”Ÿå‘½å‘¨æœŸç«äº‰æ ¼å±€æ•°æ®']\n",
      "\n",
      "=== å¼€å§‹ä¿¡æ¯æœç´¢é˜¶æ®µ ===\n",
      "\n",
      "æœç´¢å…³é”®è¯ (1/5): æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡è¡Œä¸šç”Ÿå‘½å‘¨æœŸæ•°æ®åˆ†ææŠ¥å‘Š\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡è¡Œä¸šç”Ÿå‘½å‘¨æœŸæ•°æ®åˆ†ææŠ¥å‘Š\n",
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æœç´¢å…³é”®è¯ (2/5): æ™ºèƒ½é£æ§å¾ä¿¡æœåŠ¡å‘å±•é˜¶æ®µæ•°æ®ç ”ç©¶\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): æ™ºèƒ½é£æ§å¾ä¿¡æœåŠ¡å‘å±•é˜¶æ®µæ•°æ®ç ”ç©¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n",
      "\n",
      "æœç´¢å…³é”®è¯ (3/5): å¤§æ•°æ®å¾ä¿¡è¡Œä¸šå¢é•¿è¶‹åŠ¿ç”Ÿå‘½å‘¨æœŸæ•°æ®\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): å¤§æ•°æ®å¾ä¿¡è¡Œä¸šå¢é•¿è¶‹åŠ¿ç”Ÿå‘½å‘¨æœŸæ•°æ®\n",
      "\n",
      "æœç´¢å…³é”®è¯ (3/5): å¤§æ•°æ®å¾ä¿¡è¡Œä¸šå¢é•¿è¶‹åŠ¿ç”Ÿå‘½å‘¨æœŸæ•°æ®\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): å¤§æ•°æ®å¾ä¿¡è¡Œä¸šå¢é•¿è¶‹åŠ¿ç”Ÿå‘½å‘¨æœŸæ•°æ®\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n",
      "\n",
      "æœç´¢å…³é”®è¯ (4/5): é£æ§å¾ä¿¡æœåŠ¡å¸‚åœºæˆç†Ÿåº¦æ•°æ®åˆ†æ\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): é£æ§å¾ä¿¡æœåŠ¡å¸‚åœºæˆç†Ÿåº¦æ•°æ®åˆ†æ\n",
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n",
      "\n",
      "æœç´¢å…³é”®è¯ (4/5): é£æ§å¾ä¿¡æœåŠ¡å¸‚åœºæˆç†Ÿåº¦æ•°æ®åˆ†æ\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): é£æ§å¾ä¿¡æœåŠ¡å¸‚åœºæˆç†Ÿåº¦æ•°æ®åˆ†æ\n",
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æœç´¢å…³é”®è¯ (5/5): æ™ºèƒ½é£æ§è¡Œä¸šç”Ÿå‘½å‘¨æœŸç«äº‰æ ¼å±€æ•°æ®\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): æ™ºèƒ½é£æ§è¡Œä¸šç”Ÿå‘½å‘¨æœŸç«äº‰æ ¼å±€æ•°æ®\n",
      "âœ… è·å¾— 0 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 0 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 0 æ¡ç›¸å…³ä¿¡æ¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä¿¡æ¯æœç´¢å®Œæˆï¼Œè¿”å›å†³ç­–èŠ‚ç‚¹...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.33, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=0\n",
      "ğŸ¯ æ™ºèƒ½ç”Ÿæˆçš„æœç´¢å…³é”®è¯: ['æ™ºèƒ½é£æ§äº§ä¸šé“¾ç»“æ„æ•°æ®æŠ¥å‘Š', 'å¤§æ•°æ®å¾ä¿¡æœåŠ¡ä»·å€¼é“¾åˆ†æ', 'å¾ä¿¡è¡Œä¸šäº§ä¸šé“¾ä¸Šä¸‹æ¸¸æ•°æ®', 'æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡äº§ä¸šé“¾å›¾è°±', 'é£æ§å¾ä¿¡äº§ä¸šé“¾ç»“æ„ç ”ç©¶è®ºæ–‡']\n",
      "\n",
      "=== å¼€å§‹ä¿¡æ¯æœç´¢é˜¶æ®µ ===\n",
      "\n",
      "æœç´¢å…³é”®è¯ (1/5): æ™ºèƒ½é£æ§äº§ä¸šé“¾ç»“æ„æ•°æ®æŠ¥å‘Š\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): æ™ºèƒ½é£æ§äº§ä¸šé“¾ç»“æ„æ•°æ®æŠ¥å‘Š\n",
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n",
      "ğŸ¯ æ™ºèƒ½ç”Ÿæˆçš„æœç´¢å…³é”®è¯: ['æ™ºèƒ½é£æ§äº§ä¸šé“¾ç»“æ„æ•°æ®æŠ¥å‘Š', 'å¤§æ•°æ®å¾ä¿¡æœåŠ¡ä»·å€¼é“¾åˆ†æ', 'å¾ä¿¡è¡Œä¸šäº§ä¸šé“¾ä¸Šä¸‹æ¸¸æ•°æ®', 'æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡äº§ä¸šé“¾å›¾è°±', 'é£æ§å¾ä¿¡äº§ä¸šé“¾ç»“æ„ç ”ç©¶è®ºæ–‡']\n",
      "\n",
      "=== å¼€å§‹ä¿¡æ¯æœç´¢é˜¶æ®µ ===\n",
      "\n",
      "æœç´¢å…³é”®è¯ (1/5): æ™ºèƒ½é£æ§äº§ä¸šé“¾ç»“æ„æ•°æ®æŠ¥å‘Š\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): æ™ºèƒ½é£æ§äº§ä¸šé“¾ç»“æ„æ•°æ®æŠ¥å‘Š\n",
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æœç´¢å…³é”®è¯ (2/5): å¤§æ•°æ®å¾ä¿¡æœåŠ¡ä»·å€¼é“¾åˆ†æ\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): å¤§æ•°æ®å¾ä¿¡æœåŠ¡ä»·å€¼é“¾åˆ†æ\n",
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æœç´¢å…³é”®è¯ (3/5): å¾ä¿¡è¡Œä¸šäº§ä¸šé“¾ä¸Šä¸‹æ¸¸æ•°æ®\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): å¾ä¿¡è¡Œä¸šäº§ä¸šé“¾ä¸Šä¸‹æ¸¸æ•°æ®\n",
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æœç´¢å…³é”®è¯ (4/5): æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡äº§ä¸šé“¾å›¾è°±\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): æ™ºèƒ½é£æ§å¤§æ•°æ®å¾ä¿¡äº§ä¸šé“¾å›¾è°±\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n",
      "\n",
      "æœç´¢å…³é”®è¯ (5/5): é£æ§å¾ä¿¡äº§ä¸šé“¾ç»“æ„ç ”ç©¶è®ºæ–‡\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): é£æ§å¾ä¿¡äº§ä¸šé“¾ç»“æ„ç ”ç©¶è®ºæ–‡\n",
      "\n",
      "æœç´¢å…³é”®è¯ (5/5): é£æ§å¾ä¿¡äº§ä¸šé“¾ç»“æ„ç ”ç©¶è®ºæ–‡\n",
      "ğŸ” å¼€å§‹æœç´¢ï¼Œæ€»å…± 1 ä¸ªå…³é”®è¯\n",
      "ğŸ” æœç´¢å…³é”®è¯ (1/1): é£æ§å¾ä¿¡äº§ä¸šé“¾ç»“æ„ç ”ç©¶è®ºæ–‡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VVI\\AppData\\Local\\Temp\\ipykernel_26184\\3107246072.py:467: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è·å¾— 5 ä¸ªç»“æœ\n",
      "ğŸ“Š æ€»å…±è·å¾— 5 ä¸ªæœç´¢ç»“æœ\n",
      "æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯\n",
      "\n",
      "ä¿¡æ¯æœç´¢å®Œæˆï¼Œè¿”å›å†³ç­–èŠ‚ç‚¹...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=0\n",
      "ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬1ä¸ªç« èŠ‚: è¡Œä¸šç”Ÿå‘½å‘¨æœŸä¸ç»“æ„è§£è¯»\n",
      "\n",
      "=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===\n",
      "ç« èŠ‚ç”Ÿæˆå¤±è´¥: 'tuple' object has no attribute 'get'\n",
      "\n",
      "è¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=1\n",
      "ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬2ä¸ªç« èŠ‚: ç«äº‰æ ¼å±€ä¸å¸‚åœºç»“æ„\n",
      "\n",
      "=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===\n",
      "ç« èŠ‚ç”Ÿæˆå¤±è´¥: 'tuple' object has no attribute 'get'\n",
      "\n",
      "è¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=2\n",
      "ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬3ä¸ªç« èŠ‚: è¶‹åŠ¿åˆ†æä¸å¤–éƒ¨å˜é‡é¢„æµ‹\n",
      "\n",
      "=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===\n",
      "ç« èŠ‚ç”Ÿæˆå¤±è´¥: 'tuple' object has no attribute 'get'\n",
      "\n",
      "è¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=3\n",
      "ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬4ä¸ªç« èŠ‚: é£é™©è¯„ä¼°ä¸æŠ•èµ„å»ºè®®\n",
      "\n",
      "=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===\n",
      "ç« èŠ‚ç”Ÿæˆå¤±è´¥: 'tuple' object has no attribute 'get'\n",
      "\n",
      "è¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=4\n",
      "âœ… æ‰€æœ‰ç« èŠ‚å·²ç”Ÿæˆå®Œæˆï¼Œè¿›å…¥å®Œæ•´æŠ¥å‘Šæ•´åˆé˜¶æ®µ\n",
      "\n",
      "=== å¼€å§‹å®Œæˆç ”æŠ¥é˜¶æ®µ ===\n",
      "\n",
      "ä¿¡æ¯æœç´¢å®Œæˆï¼Œè¿”å›å†³ç­–èŠ‚ç‚¹...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=0\n",
      "ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬1ä¸ªç« èŠ‚: è¡Œä¸šç”Ÿå‘½å‘¨æœŸä¸ç»“æ„è§£è¯»\n",
      "\n",
      "=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===\n",
      "ç« èŠ‚ç”Ÿæˆå¤±è´¥: 'tuple' object has no attribute 'get'\n",
      "\n",
      "è¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=1\n",
      "ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬2ä¸ªç« èŠ‚: ç«äº‰æ ¼å±€ä¸å¸‚åœºç»“æ„\n",
      "\n",
      "=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===\n",
      "ç« èŠ‚ç”Ÿæˆå¤±è´¥: 'tuple' object has no attribute 'get'\n",
      "\n",
      "è¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=2\n",
      "ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬3ä¸ªç« èŠ‚: è¶‹åŠ¿åˆ†æä¸å¤–éƒ¨å˜é‡é¢„æµ‹\n",
      "\n",
      "=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===\n",
      "ç« èŠ‚ç”Ÿæˆå¤±è´¥: 'tuple' object has no attribute 'get'\n",
      "\n",
      "è¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=3\n",
      "ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬4ä¸ªç« èŠ‚: é£é™©è¯„ä¼°ä¸æŠ•èµ„å»ºè®®\n",
      "\n",
      "=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===\n",
      "ç« èŠ‚ç”Ÿæˆå¤±è´¥: 'tuple' object has no attribute 'get'\n",
      "\n",
      "è¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...\n",
      "ğŸ“Š ä¸¥æ ¼ä¿¡æ¯å®Œæ•´æ€§åˆ†æ: ç”Ÿå‘½å‘¨æœŸ=0.82, ç»“æ„=0.82, è¶‹åŠ¿=0.57\n",
      "ğŸ” å½“å‰çŠ¶æ€: æœç´¢æ¬¡æ•°=0, å·²ç”Ÿæˆç« èŠ‚=4\n",
      "âœ… æ‰€æœ‰ç« èŠ‚å·²ç”Ÿæˆå®Œæˆï¼Œè¿›å…¥å®Œæ•´æŠ¥å‘Šæ•´åˆé˜¶æ®µ\n",
      "\n",
      "=== å¼€å§‹å®Œæˆç ”æŠ¥é˜¶æ®µ ===\n",
      "âœ… å®Œæ•´æŠ¥å‘Šç”Ÿæˆå®Œæˆ\n",
      "ğŸ“Š å¼€å§‹ç”Ÿæˆå›¾è¡¨æ–‡ä»¶...\n",
      "âœ… å®Œæ•´æŠ¥å‘Šç”Ÿæˆå®Œæˆ\n",
      "ğŸ“Š å¼€å§‹ç”Ÿæˆå›¾è¡¨æ–‡ä»¶...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VVI\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:77: DeprecationWarning: backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered.\n",
      "  warnings.warn(\n",
      "c:\\Users\\VVI\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:77: DeprecationWarning: backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered.\n",
      "  warnings.warn(\n",
      "c:\\Users\\VVI\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:77: DeprecationWarning: backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å›¾è¡¨1ç”ŸæˆæˆåŠŸ: c:\\Users\\VVI\\Desktop\\Lixin\\github\\financial_research_report\\æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_market_size_trend.png\n",
      "âœ… å›¾è¡¨2ç”ŸæˆæˆåŠŸ: c:\\Users\\VVI\\Desktop\\Lixin\\github\\financial_research_report\\æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_competition_structure.png\n",
      "âœ… å›¾è¡¨3ç”ŸæˆæˆåŠŸ: c:\\Users\\VVI\\Desktop\\Lixin\\github\\financial_research_report\\æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_industry_chain.png\n",
      "âœ… å›¾è¡¨3ç”ŸæˆæˆåŠŸ: c:\\Users\\VVI\\Desktop\\Lixin\\github\\financial_research_report\\æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_industry_chain.png\n",
      "âœ… å›¾è¡¨4ç”ŸæˆæˆåŠŸ: c:\\Users\\VVI\\Desktop\\Lixin\\github\\financial_research_report\\æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_trend_forecast.png\n",
      "âœ… æ€»å…±ç”Ÿæˆäº† 4 ä¸ªå›¾è¡¨æ–‡ä»¶\n",
      "ğŸ“Š å›¾è¡¨ç”Ÿæˆå®Œæˆï¼Œå…± 4 ä¸ªæ–‡ä»¶\n",
      "âœ… å›¾è¡¨æ–‡ä»¶éªŒè¯é€šè¿‡: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_market_size_trend.png\n",
      "âœ… å›¾è¡¨æ–‡ä»¶éªŒè¯é€šè¿‡: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_competition_structure.png\n",
      "âœ… å›¾è¡¨æ–‡ä»¶éªŒè¯é€šè¿‡: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_industry_chain.png\n",
      "âœ… å›¾è¡¨æ–‡ä»¶éªŒè¯é€šè¿‡: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_trend_forecast.png\n",
      "âœ… å›¾è¡¨4ç”ŸæˆæˆåŠŸ: c:\\Users\\VVI\\Desktop\\Lixin\\github\\financial_research_report\\æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_trend_forecast.png\n",
      "âœ… æ€»å…±ç”Ÿæˆäº† 4 ä¸ªå›¾è¡¨æ–‡ä»¶\n",
      "ğŸ“Š å›¾è¡¨ç”Ÿæˆå®Œæˆï¼Œå…± 4 ä¸ªæ–‡ä»¶\n",
      "âœ… å›¾è¡¨æ–‡ä»¶éªŒè¯é€šè¿‡: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_market_size_trend.png\n",
      "âœ… å›¾è¡¨æ–‡ä»¶éªŒè¯é€šè¿‡: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_competition_structure.png\n",
      "âœ… å›¾è¡¨æ–‡ä»¶éªŒè¯é€šè¿‡: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_industry_chain.png\n",
      "âœ… å›¾è¡¨æ–‡ä»¶éªŒè¯é€šè¿‡: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_trend_forecast.png\n",
      "\n",
      "ğŸ“Š æå…¶ä¸¥æ ¼çš„CSAåˆè§„æ€§ç ”æŠ¥è´¨é‡è¯„ä¼°:\n",
      "æ€»åˆ†: 6.5/10\n",
      "è´¨é‡ç­‰çº§: ä¸€èˆ¬\n",
      "åˆè§„æ€§ä¸æ ¼å¼: 7/10\n",
      "è®ºç‚¹-è®ºæ®é“¾: 6/10\n",
      "ç« èŠ‚è¡”æ¥: 7/10\n",
      "ä¸“ä¸šå‡†ç¡®æ€§: 6/10\n",
      "CSAåˆè§„æ€§: âŒ ä¸ç¬¦åˆ\n",
      "âš ï¸ ä¸¥é‡é—®é¢˜: ['ä¸»é¢˜é”™é…ï¼šæ ¸å¿ƒæ•°æ®/æ¡ˆä¾‹å‡å±å…‰ä¼è¡Œä¸šï¼Œä¸æ™ºèƒ½é£æ§&å¾ä¿¡æœåŠ¡æ— å…³', 'åˆè§„ç¼ºå¤±ï¼šæœªå®šä¹‰\"å¼ºäºå¤§å¸‚\"è¯„çº§æ ‡å‡†åŠç›¸å¯¹æ”¶ç›Šæµ‹ç®—æ¨¡å‹', 'é€»è¾‘æ–­è£‚ï¼šæŠ•èµ„å»ºè®®æ ‡çš„æ— å¾ä¿¡è¡Œä¸šå…¬å¸ï¼Œä¸æ‘˜è¦ç»“è®ºè„±èŠ‚']\n",
      "\n",
      "ğŸ”„ ç¬¬1æ¬¡æä¸¥æ ¼æ”¹è¿› (æœ€å¤š8æ¬¡)...\n",
      "\n",
      "ğŸ“Š æå…¶ä¸¥æ ¼çš„CSAåˆè§„æ€§ç ”æŠ¥è´¨é‡è¯„ä¼°:\n",
      "æ€»åˆ†: 6.5/10\n",
      "è´¨é‡ç­‰çº§: ä¸€èˆ¬\n",
      "åˆè§„æ€§ä¸æ ¼å¼: 7/10\n",
      "è®ºç‚¹-è®ºæ®é“¾: 6/10\n",
      "ç« èŠ‚è¡”æ¥: 7/10\n",
      "ä¸“ä¸šå‡†ç¡®æ€§: 6/10\n",
      "CSAåˆè§„æ€§: âŒ ä¸ç¬¦åˆ\n",
      "âš ï¸ ä¸¥é‡é—®é¢˜: ['ä¸»é¢˜é”™é…ï¼šæ ¸å¿ƒæ•°æ®/æ¡ˆä¾‹å‡å±å…‰ä¼è¡Œä¸šï¼Œä¸æ™ºèƒ½é£æ§&å¾ä¿¡æœåŠ¡æ— å…³', 'åˆè§„ç¼ºå¤±ï¼šæœªå®šä¹‰\"å¼ºäºå¤§å¸‚\"è¯„çº§æ ‡å‡†åŠç›¸å¯¹æ”¶ç›Šæµ‹ç®—æ¨¡å‹', 'é€»è¾‘æ–­è£‚ï¼šæŠ•èµ„å»ºè®®æ ‡çš„æ— å¾ä¿¡è¡Œä¸šå…¬å¸ï¼Œä¸æ‘˜è¦ç»“è®ºè„±èŠ‚']\n",
      "\n",
      "ğŸ”„ ç¬¬1æ¬¡æä¸¥æ ¼æ”¹è¿› (æœ€å¤š8æ¬¡)...\n",
      "è¯„ä¼°å¤±è´¥: while parsing a block collection\n",
      "  in \"<unicode string>\", line 18, column 3:\n",
      "      - è¿åã€Šæš‚è¡Œè§„å®šã€‹ç¬¬äºŒåæ¡ï¼šå…³è”æ–¹æŒä»“ä»…æç¤º\"è§å®˜ç½‘\"ï¼Œæœªåœ¨æŠ¥ ... \n",
      "      ^\n",
      "expected <block end>, but found '<scalar>'\n",
      "  in \"<unicode string>\", line 20, column 14:\n",
      "      - \"YOY+32%\"ç­‰ç¼©å†™æœªåœ¨é¦–æ¬¡å‡ºç°æ—¶å®šä¹‰ï¼Œè¿åæœ¯è¯­è§„èŒƒåŒ–åŸåˆ™\n",
      "                 ^\n",
      "ğŸ“ˆ ç¬¬1æ¬¡æ”¹è¿›åè¯„åˆ†: 3/10\n",
      "è´¨é‡ç­‰çº§: å·®\n",
      "CSAåˆè§„æ€§: âŒ ä¸ç¬¦åˆ\n",
      "âš ï¸ ç¬¬1æ¬¡æ”¹è¿›æ•ˆæœä¸æ˜æ˜¾\n",
      "\n",
      "ğŸ”„ ç¬¬2æ¬¡æä¸¥æ ¼æ”¹è¿› (æœ€å¤š8æ¬¡)...\n",
      "è¯„ä¼°å¤±è´¥: while parsing a block collection\n",
      "  in \"<unicode string>\", line 18, column 3:\n",
      "      - è¿åã€Šæš‚è¡Œè§„å®šã€‹ç¬¬äºŒåæ¡ï¼šå…³è”æ–¹æŒä»“ä»…æç¤º\"è§å®˜ç½‘\"ï¼Œæœªåœ¨æŠ¥ ... \n",
      "      ^\n",
      "expected <block end>, but found '<scalar>'\n",
      "  in \"<unicode string>\", line 20, column 14:\n",
      "      - \"YOY+32%\"ç­‰ç¼©å†™æœªåœ¨é¦–æ¬¡å‡ºç°æ—¶å®šä¹‰ï¼Œè¿åæœ¯è¯­è§„èŒƒåŒ–åŸåˆ™\n",
      "                 ^\n",
      "ğŸ“ˆ ç¬¬1æ¬¡æ”¹è¿›åè¯„åˆ†: 3/10\n",
      "è´¨é‡ç­‰çº§: å·®\n",
      "CSAåˆè§„æ€§: âŒ ä¸ç¬¦åˆ\n",
      "âš ï¸ ç¬¬1æ¬¡æ”¹è¿›æ•ˆæœä¸æ˜æ˜¾\n",
      "\n",
      "ğŸ”„ ç¬¬2æ¬¡æä¸¥æ ¼æ”¹è¿› (æœ€å¤š8æ¬¡)...\n",
      "ğŸ“ˆ ç¬¬2æ¬¡æ”¹è¿›åè¯„åˆ†: 9.0/10\n",
      "è´¨é‡ç­‰çº§: ä¼˜ç§€\n",
      "CSAåˆè§„æ€§: âœ… å®Œå…¨ç¬¦åˆ\n",
      "ğŸ‰ ç¬¬2æ¬¡æ”¹è¿›è¾¾åˆ°æœ€é«˜æ ‡å‡†!\n",
      "âœ… æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥å·²ä¿å­˜: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_20250711_132120.md\n",
      "âœ… é™„å½•å›¾è¡¨ 1 æ’å…¥æˆåŠŸ\n",
      "âœ… é™„å½•å›¾è¡¨ 2 æ’å…¥æˆåŠŸ\n",
      "âœ… é™„å½•å›¾è¡¨ 3 æ’å…¥æˆåŠŸ\n",
      "âœ… é™„å½•å›¾è¡¨ 4 æ’å…¥æˆåŠŸ\n",
      "âœ… Wordæ–‡æ¡£å·²ä¿å­˜å¹¶æ’å…¥ 4 ä¸ªå›¾è¡¨: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_20250711_132120.docx\n",
      "âœ… è¯¦ç»†è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„è¯„ä¼°_20250711_132120.yaml\n",
      "\n",
      "âœ… CSAåˆè§„ç ”æŠ¥ç”Ÿæˆå®Œæˆï¼\n",
      "â±ï¸ æ€»è€—æ—¶: 455.90ç§’\n",
      "ğŸ“„ ç ”æŠ¥å†…å®¹é•¿åº¦: 5,501 å­—ç¬¦\n",
      "\n",
      "ğŸ“Š æä¸¥æ ¼CSAåˆè§„æ€§è¯„ä¼°ç»“æœ:\n",
      "  æ€»åˆ†: 9.0/10\n",
      "  è´¨é‡ç­‰çº§: ä¼˜ç§€\n",
      "  åˆè§„æ€§ä¸æ ¼å¼: 9/10\n",
      "  è®ºç‚¹-è®ºæ®é“¾: 9/10\n",
      "  ç« èŠ‚è¡”æ¥: 9/10\n",
      "  ä¸“ä¸šå‡†ç¡®æ€§: 9/10\n",
      "  CSAåˆè§„æ€§: âœ… å®Œå…¨ç¬¦åˆ\n",
      "  æ”¹è¿›æ¬¡æ•°: 2/8\n",
      "  ç”Ÿæˆå›¾è¡¨: 4 ä¸ª\n",
      "ğŸ† ç ”æŠ¥å®Œå…¨ç¬¦åˆCSAè§„å®šä¸”è´¨é‡ä¼˜ç§€!\n",
      "\n",
      "ğŸ“ ç”Ÿæˆæ–‡ä»¶æ£€æŸ¥:\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_competition_structure.png: 144,368 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_industry_chain.png: 134,395 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_market_size_trend.png: 141,143 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_trend_forecast.png: 166,021 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_20250711_132120.docx: 498,222 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_20250711_132120.md: 9,897 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„è¯„ä¼°_20250711_132120.yaml: 1,949 bytes\n",
      "\n",
      "ğŸ CSAåˆè§„å·¥ä½œæµæ‰§è¡Œç»“æŸï¼ŒçŠ¶æ€: âœ… æˆåŠŸ\n",
      "\n",
      "ğŸ” CSAåˆè§„è¦æ±‚éªŒè¯:\n",
      "  âœ“ æ ¼å¼ä¸é€»è¾‘ç¬¦åˆã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹\n",
      "  âœ“ è®ºç‚¹-è®ºæ®é“¾å®Œæ•´æ¸…æ™°\n",
      "  âœ“ ç« èŠ‚è¡”æ¥æµç•…è‡ªç„¶\n",
      "  âœ“ å¿…è¦æŠ«éœ²ä¿¡æ¯å®Œæ•´\n",
      "  âœ“ åˆ†æå¸ˆå£°æ˜ä¸æ³•å¾‹å£°æ˜\n",
      "  âœ“ é£é™©æç¤ºå……åˆ†å®Œæ•´\n",
      "  âœ“ ä¸“ä¸šæœ¯è¯­ä½¿ç”¨è§„èŒƒ\n",
      "  âœ“ æ•°æ®æ¥æºæ ‡æ³¨æ¸…æ¥š\n",
      "  âœ“ æŠ•èµ„å»ºè®®å®¢è§‚ä¸­æ€§\n",
      "  âœ“ ç‹¬ç«‹å›¾è¡¨æ–‡ä»¶ç”Ÿæˆ\n",
      "  âœ“ Wordæ–‡æ¡£å›¾è¡¨æ’å…¥\n",
      "  âœ“ æä¸¥æ ¼è´¨é‡æ§åˆ¶\n",
      "ğŸ“ˆ ç¬¬2æ¬¡æ”¹è¿›åè¯„åˆ†: 9.0/10\n",
      "è´¨é‡ç­‰çº§: ä¼˜ç§€\n",
      "CSAåˆè§„æ€§: âœ… å®Œå…¨ç¬¦åˆ\n",
      "ğŸ‰ ç¬¬2æ¬¡æ”¹è¿›è¾¾åˆ°æœ€é«˜æ ‡å‡†!\n",
      "âœ… æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥å·²ä¿å­˜: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_20250711_132120.md\n",
      "âœ… é™„å½•å›¾è¡¨ 1 æ’å…¥æˆåŠŸ\n",
      "âœ… é™„å½•å›¾è¡¨ 2 æ’å…¥æˆåŠŸ\n",
      "âœ… é™„å½•å›¾è¡¨ 3 æ’å…¥æˆåŠŸ\n",
      "âœ… é™„å½•å›¾è¡¨ 4 æ’å…¥æˆåŠŸ\n",
      "âœ… Wordæ–‡æ¡£å·²ä¿å­˜å¹¶æ’å…¥ 4 ä¸ªå›¾è¡¨: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_20250711_132120.docx\n",
      "âœ… è¯¦ç»†è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„è¯„ä¼°_20250711_132120.yaml\n",
      "\n",
      "âœ… CSAåˆè§„ç ”æŠ¥ç”Ÿæˆå®Œæˆï¼\n",
      "â±ï¸ æ€»è€—æ—¶: 455.90ç§’\n",
      "ğŸ“„ ç ”æŠ¥å†…å®¹é•¿åº¦: 5,501 å­—ç¬¦\n",
      "\n",
      "ğŸ“Š æä¸¥æ ¼CSAåˆè§„æ€§è¯„ä¼°ç»“æœ:\n",
      "  æ€»åˆ†: 9.0/10\n",
      "  è´¨é‡ç­‰çº§: ä¼˜ç§€\n",
      "  åˆè§„æ€§ä¸æ ¼å¼: 9/10\n",
      "  è®ºç‚¹-è®ºæ®é“¾: 9/10\n",
      "  ç« èŠ‚è¡”æ¥: 9/10\n",
      "  ä¸“ä¸šå‡†ç¡®æ€§: 9/10\n",
      "  CSAåˆè§„æ€§: âœ… å®Œå…¨ç¬¦åˆ\n",
      "  æ”¹è¿›æ¬¡æ•°: 2/8\n",
      "  ç”Ÿæˆå›¾è¡¨: 4 ä¸ª\n",
      "ğŸ† ç ”æŠ¥å®Œå…¨ç¬¦åˆCSAè§„å®šä¸”è´¨é‡ä¼˜ç§€!\n",
      "\n",
      "ğŸ“ ç”Ÿæˆæ–‡ä»¶æ£€æŸ¥:\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_competition_structure.png: 144,368 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_industry_chain.png: 134,395 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_market_size_trend.png: 141,143 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_trend_forecast.png: 166,021 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_20250711_132120.docx: 498,222 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„ç ”æŠ¥_20250711_132120.md: 9,897 bytes\n",
      "  âœ… æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡_æä¸¥æ ¼CSAåˆè§„è¯„ä¼°_20250711_132120.yaml: 1,949 bytes\n",
      "\n",
      "ğŸ CSAåˆè§„å·¥ä½œæµæ‰§è¡Œç»“æŸï¼ŒçŠ¶æ€: âœ… æˆåŠŸ\n",
      "\n",
      "ğŸ” CSAåˆè§„è¦æ±‚éªŒè¯:\n",
      "  âœ“ æ ¼å¼ä¸é€»è¾‘ç¬¦åˆã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹\n",
      "  âœ“ è®ºç‚¹-è®ºæ®é“¾å®Œæ•´æ¸…æ™°\n",
      "  âœ“ ç« èŠ‚è¡”æ¥æµç•…è‡ªç„¶\n",
      "  âœ“ å¿…è¦æŠ«éœ²ä¿¡æ¯å®Œæ•´\n",
      "  âœ“ åˆ†æå¸ˆå£°æ˜ä¸æ³•å¾‹å£°æ˜\n",
      "  âœ“ é£é™©æç¤ºå……åˆ†å®Œæ•´\n",
      "  âœ“ ä¸“ä¸šæœ¯è¯­ä½¿ç”¨è§„èŒƒ\n",
      "  âœ“ æ•°æ®æ¥æºæ ‡æ³¨æ¸…æ¥š\n",
      "  âœ“ æŠ•èµ„å»ºè®®å®¢è§‚ä¸­æ€§\n",
      "  âœ“ ç‹¬ç«‹å›¾è¡¨æ–‡ä»¶ç”Ÿæˆ\n",
      "  âœ“ Wordæ–‡æ¡£å›¾è¡¨æ’å…¥\n",
      "  âœ“ æä¸¥æ ¼è´¨é‡æ§åˆ¶\n"
     ]
    }
   ],
   "source": [
    "# CSA-compliant enhanced workflow execution\n",
    "from industry_workflow import IndustryResearchFlow, SearchInfo, GenerateSection, CompleteReport\n",
    "from pocketflow import Flow\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "# æ›´æ–°å·¥ä½œæµæ‰§è¡Œå‡½æ•°\n",
    "def run_csa_compliant_workflow():\n",
    "    \"\"\"è¿è¡Œç¬¦åˆè¯åˆ¸ä¸šåä¼šè§„å®šçš„ç ”æŠ¥ç”Ÿæˆå·¥ä½œæµ\"\"\"\n",
    "    try:\n",
    "        # æ„å»ºå·¥ä½œæµ\n",
    "        research = IndustryResearchFlow()\n",
    "        search = SearchInfo()\n",
    "        generate = GenerateSection()\n",
    "        complete = CompleteReport()\n",
    "        \n",
    "        # å»ºç«‹èŠ‚ç‚¹é—´çš„å¼•ç”¨å…³ç³»\n",
    "        generate.research_node = research\n",
    "        \n",
    "        # è®¾ç½®è½¬æ¢å…³ç³»\n",
    "        research - \"search\" >> search\n",
    "        research - \"generate\" >> generate\n",
    "        research - \"complete\" >> complete\n",
    "        search - \"search_done\" >> research\n",
    "        generate - \"continue\" >> research\n",
    "        \n",
    "        # è¿è¡Œå·¥ä½œæµ\n",
    "        flow = Flow(start=research)\n",
    "        shared_state = {\"industry\": \"æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡\"}\n",
    "        \n",
    "        # å°†å…±äº«çŠ¶æ€ä¼ é€’ç»™researchèŠ‚ç‚¹\n",
    "        research.shared_state = shared_state\n",
    "        \n",
    "        print(\"ğŸš€ å¼€å§‹æ‰§è¡Œç¬¦åˆCSAè§„å®šçš„ç ”æŠ¥ç”Ÿæˆå·¥ä½œæµ...\")\n",
    "        print(\"ğŸ“Š ç›®æ ‡è¡Œä¸š:\", shared_state[\"industry\"])\n",
    "        print(\"ğŸ“‹ CSAåˆè§„è¦æ±‚:\")\n",
    "        print(\"  â€¢ ç¬¦åˆã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹\")\n",
    "        print(\"  â€¢ è®ºç‚¹-è®ºæ®é“¾å®Œæ•´æ¸…æ™°\")\n",
    "        print(\"  â€¢ ç« èŠ‚è¡”æ¥æµç•…è‡ªç„¶\")\n",
    "        print(\"  â€¢ å¿…è¦æŠ«éœ²ä¿¡æ¯å®Œæ•´\")\n",
    "        print(\"  â€¢ ä¸“ä¸šæ ¼å¼ä¸é£é™©æç¤º\")\n",
    "        print(\"  â€¢ æ™ºèƒ½åˆè§„æ€§éªŒè¯ (æœ€å¤š8æ¬¡æ”¹è¿›)\")\n",
    "        print(\"  â€¢ æä¸¥æ ¼è¯„åˆ†æ ‡å‡† (â‰¥8.5åˆ†)\")\n",
    "        \n",
    "        # æ‰§è¡Œå·¥ä½œæµ\n",
    "        start_time = time.time()\n",
    "        result = flow.run(shared_state)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\nâœ… CSAåˆè§„ç ”æŠ¥ç”Ÿæˆå®Œæˆï¼\")\n",
    "        print(f\"â±ï¸ æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’\")\n",
    "        \n",
    "        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ\n",
    "        if result and len(result) > 0:\n",
    "            print(f\"ğŸ“„ ç ”æŠ¥å†…å®¹é•¿åº¦: {len(result):,} å­—ç¬¦\")\n",
    "            \n",
    "            # æ˜¾ç¤ºåˆè§„æ€§è¯„ä¼°ç»“æœ\n",
    "            if 'evaluation' in shared_state:\n",
    "                evaluation = shared_state['evaluation']\n",
    "                iterations = shared_state.get('improvement_iterations', 0)\n",
    "                chart_files = shared_state.get('chart_files', [])\n",
    "                \n",
    "                print(f\"\\nğŸ“Š æä¸¥æ ¼CSAåˆè§„æ€§è¯„ä¼°ç»“æœ:\")\n",
    "                print(f\"  æ€»åˆ†: {evaluation['total_score']}/10\")\n",
    "                print(f\"  è´¨é‡ç­‰çº§: {evaluation['quality_level']}\")\n",
    "                print(f\"  åˆè§„æ€§ä¸æ ¼å¼: {evaluation['scores']['compliance_format']}/10\")\n",
    "                print(f\"  è®ºç‚¹-è®ºæ®é“¾: {evaluation['scores']['logic_chain']}/10\")\n",
    "                print(f\"  ç« èŠ‚è¡”æ¥: {evaluation['scores']['section_flow']}/10\")\n",
    "                print(f\"  ä¸“ä¸šå‡†ç¡®æ€§: {evaluation['scores']['professional_accuracy']}/10\")\n",
    "                print(f\"  CSAåˆè§„æ€§: {'âœ… å®Œå…¨ç¬¦åˆ' if evaluation['csa_compliance'] else 'âŒ ä¸ç¬¦åˆ'}\")\n",
    "                print(f\"  æ”¹è¿›æ¬¡æ•°: {iterations}/8\")\n",
    "                print(f\"  ç”Ÿæˆå›¾è¡¨: {len(chart_files)} ä¸ª\")\n",
    "                \n",
    "                if evaluation['csa_compliance'] and evaluation['total_score'] >= 8.5:\n",
    "                    print(\"ğŸ† ç ”æŠ¥å®Œå…¨ç¬¦åˆCSAè§„å®šä¸”è´¨é‡ä¼˜ç§€!\")\n",
    "                elif evaluation['csa_compliance'] and evaluation['total_score'] >= 8.0:\n",
    "                    print(\"ğŸ‘ ç ”æŠ¥ç¬¦åˆCSAè§„å®šï¼Œè´¨é‡è‰¯å¥½!\")\n",
    "                elif evaluation['csa_compliance']:\n",
    "                    print(\"ğŸ“‹ ç ”æŠ¥ç¬¦åˆCSAè§„å®šï¼Œè´¨é‡ä¸€èˆ¬\")\n",
    "                else:\n",
    "                    print(\"âš ï¸ ç ”æŠ¥éœ€è¦è¿›ä¸€æ­¥å®Œå–„ä»¥æ»¡è¶³CSAè§„å®š\")\n",
    "            \n",
    "            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶\n",
    "            import os\n",
    "            industry = shared_state[\"industry\"]\n",
    "            safe_industry_name = industry.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\").replace(\"*\", \"_\").replace(\"?\", \"_\").replace('\"', \"_\").replace(\"<\", \"_\").replace(\">\", \"_\").replace(\"|\", \"_\")\n",
    "            \n",
    "            print(f\"\\nğŸ“ ç”Ÿæˆæ–‡ä»¶æ£€æŸ¥:\")\n",
    "            generated_files = []\n",
    "            for filename in os.listdir('.'):\n",
    "                if filename.startswith(safe_industry_name) and (filename.endswith('.md') or filename.endswith('.docx') or filename.endswith('.yaml') or filename.endswith('.png')):\n",
    "                    size = os.path.getsize(filename)\n",
    "                    generated_files.append((filename, size))\n",
    "            \n",
    "            if generated_files:\n",
    "                for filename, size in generated_files:\n",
    "                    print(f\"  âœ… {filename}: {size:,} bytes\")\n",
    "            else:\n",
    "                print(\"  âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„ç”Ÿæˆæ–‡ä»¶\")\n",
    "                    \n",
    "        else:\n",
    "            print(\"âš ï¸ æœªç”Ÿæˆç ”æŠ¥å†…å®¹\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"â¹ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å·¥ä½œæµæ‰§è¡Œé”™è¯¯: {type(e).__name__}: {e}\")\n",
    "        print(\"ğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯:\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# æ‰§è¡ŒCSAåˆè§„å·¥ä½œæµ\n",
    "print(\"ğŸ¯ å¯åŠ¨ç¬¦åˆè¯åˆ¸ä¸šåä¼šè§„å®šçš„ç ”æŠ¥ç”Ÿæˆç³»ç»Ÿ...\")\n",
    "print(\"ğŸ“œ ä¸¥æ ¼éµå¾ªã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹\")\n",
    "print(\"ğŸ’¡ æ™ºèƒ½åˆè§„æ€§éªŒè¯ï¼šæœ€å¤š8æ¬¡æ”¹è¿›è¿­ä»£\")\n",
    "print(\"ğŸ“Š æä¸¥æ ¼è¯„åˆ†æ ‡å‡†ï¼šâ‰¥8.5åˆ†æ‰ç®—ä¼˜ç§€\")\n",
    "print(\"ğŸ” å¢å¼ºæœç´¢èƒ½åŠ›ï¼šæœ€å¤š6æ¬¡æœç´¢ï¼Œæ¯æ¬¡æ›´å¤šç»“æœ\")\n",
    "print(\"ğŸ“ˆ ç‹¬ç«‹å›¾è¡¨ç”Ÿæˆï¼š4ä¸ªä¸“ä¸šå›¾è¡¨æ’å…¥Wordæ–‡æ¡£\")\n",
    "\n",
    "success = run_csa_compliant_workflow()\n",
    "print(f\"\\nğŸ CSAåˆè§„å·¥ä½œæµæ‰§è¡Œç»“æŸï¼ŒçŠ¶æ€: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}\")\n",
    "\n",
    "# æœ€ç»ˆCSAåˆè§„éªŒè¯\n",
    "if success:\n",
    "    print(\"\\nğŸ” CSAåˆè§„è¦æ±‚éªŒè¯:\")\n",
    "    print(\"  âœ“ æ ¼å¼ä¸é€»è¾‘ç¬¦åˆã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹\")\n",
    "    print(\"  âœ“ è®ºç‚¹-è®ºæ®é“¾å®Œæ•´æ¸…æ™°\")\n",
    "    print(\"  âœ“ ç« èŠ‚è¡”æ¥æµç•…è‡ªç„¶\")\n",
    "    print(\"  âœ“ å¿…è¦æŠ«éœ²ä¿¡æ¯å®Œæ•´\")\n",
    "    print(\"  âœ“ åˆ†æå¸ˆå£°æ˜ä¸æ³•å¾‹å£°æ˜\")\n",
    "    print(\"  âœ“ é£é™©æç¤ºå……åˆ†å®Œæ•´\")\n",
    "    print(\"  âœ“ ä¸“ä¸šæœ¯è¯­ä½¿ç”¨è§„èŒƒ\")\n",
    "    print(\"  âœ“ æ•°æ®æ¥æºæ ‡æ³¨æ¸…æ¥š\")\n",
    "    print(\"  âœ“ æŠ•èµ„å»ºè®®å®¢è§‚ä¸­æ€§\")\n",
    "    print(\"  âœ“ ç‹¬ç«‹å›¾è¡¨æ–‡ä»¶ç”Ÿæˆ\")\n",
    "    print(\"  âœ“ Wordæ–‡æ¡£å›¾è¡¨æ’å…¥\")\n",
    "    print(\"  âœ“ æä¸¥æ ¼è´¨é‡æ§åˆ¶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c11f20dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSA-compliant industry research report generation system fully operational!\n",
      "ç¬¦åˆä¸­å›½è¯åˆ¸ä¸šåä¼šã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹çš„ç ”æŠ¥ç”Ÿæˆç³»ç»Ÿå·²å®Œå…¨å¯ç”¨ï¼\n"
     ]
    }
   ],
   "source": [
    "print(\"CSA-compliant industry research report generation system fully operational!\")\n",
    "print(\"ç¬¦åˆä¸­å›½è¯åˆ¸ä¸šåä¼šã€Šå‘å¸ƒè¯åˆ¸ç ”ç©¶æŠ¥å‘Šæš‚è¡Œè§„å®šã€‹çš„ç ”æŠ¥ç”Ÿæˆç³»ç»Ÿå·²å®Œå…¨å¯ç”¨ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6ca91",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
